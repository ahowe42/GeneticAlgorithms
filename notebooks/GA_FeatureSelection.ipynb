{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ed2952-8937-45a6-8e2a-2d572e71cc06",
   "metadata": {},
   "source": [
    "# Genetic Algorithm\n",
    "## Feature selection\n",
    "\n",
    "This notebook demonstrates feature selection with the GA for a given dataset with the goal of minimzing error from a machine learning model. The data is simulated using a known dependence structure, so it is possible to assess the accuracy of the GA result.\n",
    "\n",
    "Statistical modelers have been trying models on subsets of features for almost as long as statistical modeling (most of what we call \"machine learning\" is actually statistical modeling) has been around. Perhaps unimaginably, we call the process of selecting a subset of available features [feature selection](https://en.wikipedia.org/wiki/Feature_selection). In feature selection, we use some procedure to generate subsets of the existing features, fit a model to them, and evaluate that model to find an optimal subset. The goal of feature selection is usually to balance two considerations: model performance and model complexity. It is generally beneficial for a model to be simpler - to use fewer features, for example. We often prefer a simpler model, even if it performs slightly worse than a more complex model. This follows the principle of [occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor).\n",
    "\n",
    "A simple way to perform feature selection, that guarantees finding the most optimal subset of features, is combinatorial enumeration - a.k.a. brute force. Combinatorial enumeration does exactly what it sounds like - the model is evauated on the enumeration of all possible combinations of features. This is no mean feat, as the number of ways to combine $p$ features is exponential in $p$; there are $2^{p-1}$ possible subsets. The GA is a useful tool for feature selection; for $p$ features, each individual is a p-length binary string indicating that a feature is in that solution (1) or out of it (0). If $p=8$, for example, one solution may be $10011001$; in this case, features 1,4,5,8 will be used, while 2,3,6,7 will not.\n",
    "\n",
    "- <a href=#SD>Simulate Data</a>\n",
    "- <a href=#GA>Run GA</a>\n",
    "- <a href=#PR>Plot Results</a>\n",
    "- <a href=#end>End</a>\n",
    "\n",
    "<a id=top></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d587596-5de2-4cd8-9e14-83a81f14890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import ipdb\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "# to use plotly offline, need to initialize with a plot\\n\",\n",
    "plyoff.init_notebook_mode(connected=True)\n",
    "init = go.Figure(data=[go.Scatter({'x':[1, 2], 'y':[42, 42], 'mode':'markers'})], layout=go.Layout(title='Init', xaxis={'title':'x'}))\n",
    "plyoff.iplot(init)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea3d7e-6280-43a9-8154-036c3fcee1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my imports\n",
    "sys.path.append('../src/')\n",
    "from GA.GA import *\n",
    "from GA.Objective import *\n",
    "from Utils.Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a4ebd-fb1b-4bbd-b8ba-062703352f7f",
   "metadata": {},
   "source": [
    "### Simulate Data\n",
    "Simulate a dataset such that there is a known relationship between (some of) the features and a target variable.\n",
    "\n",
    "<a href=#top>Go to Top</a>\n",
    "<a id=SD></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28d2ea-1ce8-42e2-bf2e-f34b88f2b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate some data '''\n",
    "# data generating process parameters\n",
    "p = 20\n",
    "n = 100\n",
    "gamma = 5\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "# real features\n",
    "simSubs = np.zeros(shape=(p,), dtype=int)\n",
    "simSubs[:3] = 1\n",
    "B = np.zeros(shape=(p,), dtype=float)\n",
    "B[simSubs==1] = [8, -1, 4]\n",
    "\n",
    "# generate the features & target\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(n, p)*gamma\n",
    "noise =  np.random.normal(loc=mu, scale=sigma, size=n)\n",
    "y = np.sum(X[:,simSubs==1]*B[B != 0], axis=1)# + noise\n",
    "simName = '+'.join(['%dX%d'%(B[i], i) for (i, f) in enumerate(simSubs) if f])\n",
    "\n",
    "# create the dataframe\n",
    "feats = ['X%d'%i for i in range(p)]\n",
    "data = pd.DataFrame(data=y, columns=['target'])\n",
    "data[feats] = X\n",
    "\n",
    "# talk\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534ddba-726c-43f1-9398-87e4544ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the features correlations\n",
    "figCorr = correlationsPlot(data.corr(), plotTitl='Feature Correlations Plot',\n",
    "                           trcLims=(0.0, 0.75, 0.9, 0.95, 1.0), tweaks=(20, None, None, 1.05))\n",
    "plyoff.plot(figCorr, filename='../output/Correlations_%s.html'%(re.sub('[^0-9A-Za-z_]', '_', simName)), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d75035-5777-42aa-a0d7-300ea6b76169",
   "metadata": {},
   "source": [
    "### Run GA\n",
    "<a href=#top>Go to Top</a>\n",
    "<a id=GA></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a6699-56fe-4431-93d8-ddf708fdcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prepare GA input parameters '''\n",
    "# GA parameters\n",
    "parmsGA = {'initPerc':0.5, 'forceVars':None, 'showTopSubs':10, 'populSize':200, 'numGens':100,\n",
    "           'noChangeTerm':80, 'convgCrit':0.00001, 'elitism':True, 'mateType':2, 'probXover':0.8,\n",
    "           'probMutate':0.3, 'probEngineer':0.2, 'optimGoal':-1, 'plotFlag':True, 'printFreq':10,\n",
    "           'xoverType':1}\n",
    "# data parameters\n",
    "parmsData = {'data':data, 'name':simName}\n",
    "# objective parameters\n",
    "#estim = DecisionTreeRegressor()\n",
    "estim = LinearRegression(fit_intercept=False)\n",
    "#estim = Lasso()\n",
    "#estim = Ridge()\n",
    "parmsObj = {'function':'RegressionMetric',\n",
    "            'arguments':{'data':None, 'subset':None, 'metric':'RMSE', 'estim':estim, 'optimGoal':parmsGA['optimGoal']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d44a7c-1bf6-46ee-bd5e-acf24e9a2b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' run the GA - hold on to your butts '''\n",
    "# parameters\n",
    "randSeed = None#42\n",
    "verb = False\n",
    "MSims = 1\n",
    "\n",
    "# init\n",
    "bestSubss = [None]*MSims\n",
    "bestScores = [None]*MSims\n",
    "genBestss = [None]*MSims\n",
    "genScoress = [None]*MSims\n",
    "randSeeds = [None]*MSims\n",
    "timeStamps = [None]*MSims\n",
    "figGAProgresss = [None]*MSims\n",
    "seedSubs = []\n",
    "\n",
    "for sim in range(MSims):\n",
    "    print('Executing GA %d of %d'%(sim+1, MSims))\n",
    "    bestSubss[sim], bestScores[sim], genBestss[sim], genScoress[sim],\\\n",
    "    randSeeds[sim], timeStamps[sim], figGAProgresss[sim] = RunGASubset(parmsGA, parmsData, parmsObj, seedSubs, verb, randSeed)\n",
    "    # add the best subset to seed the next GP run, if new\n",
    "    try:\n",
    "        seedSubs.index(bestSubss[sim])\n",
    "    except ValueError:\n",
    "        # this best is new, so add\n",
    "        seedSubs.append(bestSubss[sim])\n",
    "\n",
    "# get the overall best\n",
    "bestIndx = np.argmax(parmsGA['optimGoal']*np.array(bestScores))\n",
    "bestScore = bestScores[bestIndx]\n",
    "bestSubs = bestSubss[bestIndx]\n",
    "timeStamp = timeStamps[bestIndx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a017df-2467-4542-b260-360f347fa023",
   "metadata": {},
   "source": [
    "### Plot Results\n",
    "Generate residuals-based diagnostic plots for three models, using features sets:\n",
    "\n",
    "- best subset found by the GA\n",
    "- subset with all features\n",
    "- subset used to generate the response\n",
    "\n",
    "<a href=#top>Go to Top</a>\n",
    "<a id=PR></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc2a42-eac9-4ab6-ac29-207e03381239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some objective stuff for the plots\n",
    "parmsObj['arguments']['data'] = data.copy()\n",
    "objStr = '%s(%s)'%(parmsObj['function'], ', '.join(['%s=%r'%(key, val) for (key, val) in parmsObj['arguments'].items()\\\n",
    "        if key not in ['data', 'subset']]))\n",
    "objStr = re.sub('[^0-9A-Za-z_]', '_', objStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38181d91-c6ff-4ea6-be5d-abc5453c8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' evaluate the best subset '''\n",
    "# subset name\n",
    "name = BinaryStr(bestSubs)\n",
    "\n",
    "# show the selected columns\n",
    "keep = [f for b, f in zip(bestSubs, feats) if b]\n",
    "print('Best Subset Columns: %r'%keep)\n",
    "\n",
    "# get the predictions & model\n",
    "parmsObj['arguments']['subset'] = bestSubs\n",
    "_, preds, estim = globals()[parmsObj['function']](**parmsObj['arguments'])\n",
    "\n",
    "# add the subset results & compute error\n",
    "data[name] = preds\n",
    "data['G_error'] = data['target'] - data[name]\n",
    "\n",
    "# talk\n",
    "display(data.head())\n",
    "\n",
    "# plot\n",
    "figGAPerformance = ResultsPlots(data, sequenceCol=None, responseCol='target',\n",
    "                                predCol=name, resdCol='G_error', colorCol=None,\n",
    "                                overall_title='GA Performance: %s = %0.4f'%(name, bestScore), plot_colors=('blue',)*4)\n",
    "plyoff.plot(figGAPerformance, filename='../output/GAPerformance_%s_%s_%s.html'\\\n",
    "            %(timeStamp, re.sub('[^0-9A-Za-z_]', '_', simName), objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea52ed-310f-4ac7-8900-c4f85fe8d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' evaluate the full subset '''\n",
    "# subset\n",
    "fullSubs = np.ones(shape=(p,1))\n",
    "name = BinaryStr(fullSubs)\n",
    "\n",
    "# get the predictions & model\n",
    "parmsObj['arguments']['subset'] = fullSubs.squeeze()\n",
    "fullScore, preds, estim = globals()[parmsObj['function']](**parmsObj['arguments'])\n",
    "\n",
    "# add the subset results & compute error\n",
    "data['full'] = preds\n",
    "data['F_error'] = data['target'] - data['full']\n",
    "\n",
    "# talk\n",
    "display(data.head())\n",
    "\n",
    "# plot\n",
    "figFull = ResultsPlots(data, sequenceCol=None, responseCol='target', predCol='full',\n",
    "                       resdCol='F_error', colorCol=None, overall_title='Full Model = %0.4f'%fullScore,\n",
    "                       plot_colors=('red',)*4)\n",
    "plyoff.plot(figFull, filename='../output/FullModel_%s_%s.html'\\\n",
    "            %(re.sub('[^0-9A-Za-z_]', '_', simName), objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c7d9a-56d4-45e6-9774-aaa33e8c8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' evaluate the true subset '''\n",
    "# subset\n",
    "name = BinaryStr(simSubs)\n",
    "\n",
    "# get the predictions & model\n",
    "parmsObj['arguments']['subset'] = simSubs.squeeze()\n",
    "simScore, preds, estim = globals()[parmsObj['function']](**parmsObj['arguments'])\n",
    "\n",
    "# add the subset results & compute error\n",
    "data['True'] = preds\n",
    "data['T_error'] = data['target'] - data['True']\n",
    "\n",
    "# talk\n",
    "display(data.head())\n",
    "\n",
    "# plot\n",
    "figTrue = ResultsPlots(data, sequenceCol=None, responseCol='target', predCol='True',\n",
    "                       resdCol='T_error', colorCol=None, overall_title='True Model = %0.4f'%simScore,\n",
    "                       plot_colors=('green',)*4)\n",
    "plyoff.plot(figTrue, filename='../output/TrueModel_%s_%s.html'\\\n",
    "            %(re.sub('[^0-9A-Za-z_]', '_', simName), objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e0406-a654-488f-9799-9485ea7dfa98",
   "metadata": {},
   "source": [
    "### End\n",
    "\n",
    "<a href=#top>Go to Top</a>\n",
    "<a id=end></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce556e-aabf-4bb2-9e29-2f503df62c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
