{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0669b26f-da8b-4693-9c22-f8115aeb8864",
   "metadata": {},
   "source": [
    "# Genetic Algorithms\n",
    "## Evolutionary Algorithms for Optimization\n",
    "\n",
    "- <a href=#NGFA>Non-Gradent Following Optimization Algorithms</a>\n",
    "- <a href=#GA>Genetic Algorithm</a>\n",
    "- <a href=#FSML>Feature Selection for Machine Learning</a>\n",
    "- <a href=#BFDS>Best-fitting Distribution Selection</a>\n",
    "- <a href=#MFM>Multivariate Function Minimization</a>\n",
    "\n",
    "<a id=top></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e307aa7-917b-4423-9bdc-ab63b5ad6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stt\n",
    "import pandas as pd\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "# to use plotly offline, need to initialize with a plot\\n\",\n",
    "plyoff.init_notebook_mode(connected=True)\n",
    "init = go.Figure(data=[go.Scatter({'x':[1, 2], 'y':[42, 42], 'mode':'markers'})], layout=go.Layout(title='Init', xaxis={'title':'x'}, height=100, width=100))\n",
    "plyoff.iplot(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ed8c3-0a04-464a-9e70-55c9f91125fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mathematical Optimization\n",
    "Optimization is the process of finding some numerical values that generate a minimum or maximum value for a specified function. Examples include finding the best parameters for a statistical distribution fit to some data, numerically solving differential equations, or feature selection in machine learning.\n",
    "\n",
    "There are many types and classes of optimization algorithms. Most that have been invented by mathematicianas and computer scientists rely on function derivatives / gradients. Anybody who's studied the topic even slightly will likely remember [Newton-Raphson](https://en.wikipedia.org/wiki/Newton%27s_method) or the [BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) - the latter of which even needs the second derivatives (the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)). Mathematical optimization algorithms typically iterate over two steps:\n",
    "\n",
    "1.  evaluate current solution\n",
    "2. find new solution to try\n",
    "\n",
    "A series of individual solutions are identified and evluated, until the sequence converges to a solution.\n",
    "\n",
    "Gradient-following methods can have good properties, but also two major issues.\n",
    "\n",
    "1. The first is the need to compute derivatives. This can often be very difficult - even assuming derivatives can be analytically solved - and time consuming. Furthermore, not all functions we wish to optimize even have a derivative. What is the derivative of an accuracy loss function for a [Decision Tree Classifier](https://en.wikipedia.org/wiki/Decision_tree_learning)?\n",
    "\n",
    "2. The second issue is that gradient-followers can easily get stuck in local optima, rather than finding a global optimum. Most such algorithms rely on being provided an initial value, at which value the necessary derivatives are computed to determine the direction (and perhaps distance) to find the next point to evaluate. Depending on the curvature of the function to optimize, and the initial value, the algorithm may get stuck in a local, not global, optimum.\n",
    "\n",
    "The figure generated below demonstrates this second point. The curve to be maximized has two optima with a saddle point in between. Four possible initial values are shown. When the curve's gradient is evaluated at the two $x_0$ points in red, an optimization algorithm will converge to the local optimum. The two in green will converge to the global optimum. In general, any initial value on the right side of the black vertical line will cause an optimization algorithm to converge to the global optimum; initial values to the left of it will converge to the local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b3508-3de3-43b0-a8f9-1b9fed5cb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "np.random.seed(42)\n",
    "X1 = stt.norm(loc=0, scale=1).rvs(500)\n",
    "X2 = stt.norm(loc=2, scale=0.5).rvs(500)\n",
    "data = np.r_[X1, X2]\n",
    "\n",
    "# prep for kde\n",
    "mn, mx = min(data), max(data)\n",
    "x= np.linspace(mn, mx, 200)\n",
    "\n",
    "# kde\n",
    "kde = stt.gaussian_kde(data, bw_method=0.25)\n",
    "y = kde(x)\n",
    "\n",
    "# create the annotation\n",
    "x1 = -1\n",
    "y1 = kde(x1)[0]\n",
    "ann1 = dict(x=x1, y=y1, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Local Optimum}$'%x1, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x2 = 0.40\n",
    "y2 = kde(x2)[0]\n",
    "ann2 = dict(x=x2, y=y2, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ←; Local Optimum}$'%x2, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x3 = 1.5\n",
    "y3 = kde(x3)[0]\n",
    "ann3 = dict(x=x3, y=y3, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Global Optimum}$'%x3, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x4 = 3.0\n",
    "y4 = kde(x4)[0]\n",
    "ann4 = dict(x=x4, y=y4, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ; Global Optimum}$'%x4, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x5 = 0.78698325\n",
    "y5 = kde(x5)[0]\n",
    "ann5 = dict(x=x5, y=y5, xref='x1', yref='y1', text='← Fails; Succeeds →', showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#6d72f1\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#636363\")\n",
    "\n",
    "# plot\n",
    "trcs = [go.Scatter(x=x, y=y, mode='lines', name='Kernel Density Estimate'),\n",
    "        go.Scatter(x=[x5, x5], y=[min(y), max(y)], mode='lines', line={'color':'black'})]\n",
    "fig = go.Figure(data=trcs, layout=go.Layout(title='Shortfall of Gradient Following'))\n",
    "anns = list(fig['layout']['annotations'])\n",
    "anns.extend([ann1, ann2, ann3, ann4, ann5])\n",
    "fig.update_layout( annotations=anns)\n",
    "#plyoff.plot(fig, include_mathjax='cdn')\n",
    "plyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3600b6c-f257-4268-8d85-0265dba18e9e",
   "metadata": {},
   "source": [
    "## Non-Gradent Following Optimization Algorithms\n",
    "<a id=NGFA></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "There are several types of mathematical optimization algorithms which similarly operate on a sequence of individual solutions, but don't use derivatives. I am familiar with [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing) and [Golden Section Search](https://en.wikipedia.org/wiki/Golden-section_search) opimization.\n",
    "\n",
    "There is an entirely different class of optimization algorithms which operate on ensembles of solutions - called a *population*, generally iteratively updating them in concert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb67cf5-2e9b-4f91-aadb-4b63a7afd19e",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithms\n",
    "The term [Evolutionary Algorithm (EA)](https://en.wikipedia.org/wiki/Evolutionary_algorithm) refers to a type of population-based metaheuristic optimization algorithm, and is a subset of evolutionary computation. Broadly, evolutionary algorithms are designed around concepts which come from biological evolution. There are several classes of evolutionary algorithms:\n",
    "\n",
    "- Differential Evolution\n",
    "- Evolutionary Programming\n",
    "- Evolutionary Strategy\n",
    "- Genetic Algorithm\n",
    "- Genetic Programming ([see here](https://github.com/ahowe42/baseball))\n",
    "- Learning Classifier System\n",
    "- Neuroevolution\n",
    "\n",
    "This set of lectures is focused on the Genetic Algorithm (GA), but could potentially be extended to include [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04162e2f-4de0-46aa-89a7-38967b81f865",
   "metadata": {},
   "source": [
    "## Other Gradient Eschewing Algorithms\n",
    "In addition to EA's, there are several other types of metaheuristic optimization algorithms that are based on the idea of optimizing with a population of potential solutions. These include:\n",
    "\n",
    "- [Ant Colony Optimization - or Traveling Ant Colony Optimization (TACO)](https://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms)\n",
    "- [Particle Swarm Optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization)\n",
    "- [Bees Algorithm](https://en.wikipedia.org/wiki/Bees_algorithm)\n",
    "- [Adaptive Dimensional Search](https://en.wikipedia.org/wiki/Adaptive_dimensional_search)\n",
    "- [Gaussian Adaptation](https://en.wikipedia.org/wiki/Gaussian_adaptation)\n",
    "- Harmony Search - special case of [Evolution Strategy](https://en.wikipedia.org/wiki/Evolution_strategy)\n",
    "\n",
    "I am only familiar with a few of these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0e191-3b93-4afd-88c4-bde661d6d9a9",
   "metadata": {},
   "source": [
    "## Genetic Algorithm\n",
    "<a id=GA></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "The genetic algorithm (GA) is a stochastic population-based metaheuristic optimization algorithm that borrows concepts from biological evolution. In the GA, a solution to an optimization problem is represented as a binary word of length $n$. In the GA parlance, this is metaphorically called an *individual*, or *chromosome*. Each solution is part of an ensemble of solutions which are considered together; this is called the *population*. The function to be optimized is called the *objective function*, or the *fitness function* - the latter is a metaphor to the biological concept of \"survival of the fittest\".\n",
    "\n",
    "The semantic meaning of the binary word as a solution that optimizes an objective function (an individual being the most fit in it's environment) depends on the context. For example, if the GA is being used to optimize a real-valued function, the word could be a digital representation of possible real values. The binary word could represent selection flags for a feature selection problem. In [this research article](https://www.researchgate.net/publication/301770005_Regularized_SVM_Classification_with_a_new_Complexity-Driven_Stochastic_Optimizer), I used the GA to simultaneously select a subset of features and one of 9 kernel functions for [kernel SVM classification](https://en.wikipedia.org/wiki/Support-vector_machine). The same binary word had one portion interpreted as binary flags, and the other portion as digital representations of the numbers 1 to 9.\n",
    "\n",
    "The objective function is usually a map, $\\phi\\left(X\\in\\mathcal{R}^{m\\times p}, I^n\\right) \\rightarrow \\mathcal{R}$, jointly mapping some data plus a binary word to a scalar real value. GAs have also been developed for multi-objective optimization, in which case the objective function would map to a real-valued vector of length $q$: $\\phi\\left(X\\in\\mathcal{R}^{m\\times p}, I^n\\right) \\rightarrow \\mathcal{R}^q$. There are several approaches to this - I find approaches that use a [Pareto Front](https://en.wikipedia.org/wiki/Pareto_front) quite appealing.\n",
    "\n",
    "Almost all optimization algorithms need to start with an initial solution, and the same is true for the GA (and indeed, all Evolutionary Algorithms). For the GA, there may be domain knowledge-based ways to generate an initial population of $P$ individuals. However, it is common to initialize the population randomly, such that each bit has a 50% chance of being turned on.\n",
    "\n",
    "Starting from the initial population, the GA iterates over a few steps:\n",
    "\n",
    "1. score the fitness of each individual in the population\n",
    "2. rank and select individuals for mating\n",
    "3. mate pairs of individuals to create a new population\n",
    "\n",
    "    a. crossover\n",
    "    \n",
    "    b. mutation\n",
    "    \n",
    "    c. GA engineering\n",
    "4. apply any other GA operators\n",
    "\n",
    "Each population of individuals is called a *generation*. There are several ways to rank and select individuals for mating. There are also several operators that can be used in the GA, mostly related to creating a new generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fde684-46b8-40e2-8261-8098c9d8c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print individuals\n",
    "printIndiv = lambda x: ''.join(['%d'%i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce1b15-776a-4fc6-a15e-cc1cd5d7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate a sample population with scores '''\n",
    "# generate the population and scores\n",
    "n = 10\n",
    "P = 8\n",
    "np.random.seed(1906)\n",
    "population = np.random.rand(P, n) > 0.5\n",
    "fitness = np.random.rand(P)\n",
    "\n",
    "# sort\n",
    "stdIndex = np.argsort(fitness)[::-1]\n",
    "population = population[stdIndex]\n",
    "fitness = fitness[stdIndex]\n",
    "\n",
    "# talk\n",
    "print('Sample population with %d %d-length individuals'%(P,n))\n",
    "for indx, (score, individual) in enumerate(zip(fitness, population)):\n",
    "    print('%d: %s = %0.3f'%(indx, printIndiv(individual), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b1fa4-51b2-4a6b-a2c7-52853198aa4b",
   "metadata": {},
   "source": [
    "### Mating Ranking & Selection\n",
    "In the GA, mating is the process of combining two individuals to generate new individuals. I generally have two *parent* solutions mate to create a pair of *child* solutions. I do this is to keep a constant population size, but it's not required. For example, mating could choose to create, based on a randomized choice either:\n",
    "\n",
    "- a single offspring + new random individual\n",
    "- a pair of offspring\n",
    "\n",
    "The new random individual in the first option could be thought of as *adoption*, and would help explore the solution space. Note that I generally use an even population size, as it simplifies this step.\n",
    "\n",
    "If the GA is being run to optimize multiple objectives, this is the part of the algorithm that is most affected, as fitness scores are predominantly used to determine which individuals mate. I have generally used two approaches to mating ranking & selection - both of the below are more complicated for multi-objective problems.\n",
    "\n",
    "#### Sorted\n",
    "In biology, it is often the case that individuals that are similarly fit for their environment mate together (hence, the phrase \"she's out of my league\"). The metaphor generally holds for the GA, in that solutions with similar objective function scores are mated. This doesn't have to be the case. For example, we could mate pairs of solutions best-fitness to worst-fitness. This approach may help better explore the solution space, but I've never used it. \n",
    "\n",
    "The sorted approach to mate ranking and selection is simple, and has the property that each individual mates exactly and only one time. For this, all individuals are sorted according to their fitness scores, then paired off in sequence, so there are $P/2$ mating pairs generated.\n",
    "\n",
    "#### Roulette\n",
    "In biology, it is often the case that the most fit individuals mate the most, thus propagating their successful genes. This metaphor holds by design with the roulette method for generating mating pairs.\n",
    "\n",
    "The roulette method starts by sorting all individuals according to their fitness scores, then generating a biased roulette bar, in which the individual bins are of gradually decreasing size as computed and visualized (for $P=4$) here:\n",
    "\\begin{equation}\n",
    "b_i = \\frac{2i}{n\\left(n+1\\right)}, i=1,\\ldots,P\\text{.}\n",
    "\\end{equation}\n",
    "\n",
    "<center><img src='../images/roulette_selection.png' width='400' height='200'></center>\n",
    "\n",
    "When the cumulative sum of these bin widths is computed, we get upper bounds for the roulette bins, which completely partition the $[0, 1]$ interval. Each bin corresponds to an individual in the population; since the population was already sorted by fitness score, the wider bins correspond to the most fit individuals.\n",
    "\n",
    "Since we don't want the population to grow, we will generate $P/2$ mating pairs. To do so, $P$ random numbers are generated uniformly from $[0, 1]$ ($U\\left(0, 1\\right)$) and placed in the appropriate bin. For each random variate in the $i^\\text{th}$ bin, the corresponding individual will be selected to mate. In this way, individuals with a better fitness score are overrepresented in the mating pool. The last step is to randomly permute the ordering of the individuals in the mating pool.\n",
    "\n",
    "Note that this means that, while the most fit individuals will tend to mate the most frequently, they won't just mate with individuals with similar fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ac71e-7341-463f-8b48-57a3d0124710",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - sorted method '''\n",
    "# skipping sorting, as the population is already sorted\n",
    "pairs = np.reshape(range(P), (P//2, 2))\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26e359-8f05-4564-a0be-c386f0e996fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - roulette method '''\n",
    "# generate the bounds and show the bins\n",
    "binUBounds = np.cumsum(2*np.linspace(P, 1, P)/(P*(P + 1.0)))\n",
    "bnds = [0] + binUBounds.tolist()\n",
    "print('Roulette bins: %r'%[('%0.2f'%f, '%0.2f'%t) for f, t in zip(bnds[:-1], bnds[1:])])\n",
    "\n",
    "# generate mating frequencies\n",
    "np.random.seed(2022)\n",
    "rands_in_bins = np.repeat(np.random.rand(P), P) >= np.tile(binUBounds, P)\n",
    "pairs = np.reshape(np.random.permutation(np.sum(np.reshape(rands_in_bins, [P]*2), axis=1)), (P//2, 2))\n",
    "\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7ecdb-5f18-4300-82c9-dc3459bf445b",
   "metadata": {},
   "source": [
    "### Crossover\n",
    "In biology, when a pair of individuals mate, their chromosomes are combined in a process called [chromosomal crossover](https://en.wikipedia.org/wiki/Chromosomal_crossover). An illustration from 1916 by researcher Thomus Hunt Morgan demonstrates the creation of recombinant genes through this process.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/0/0e/Morgan_crossover_1.jpg' height='500' width='500'>\n",
    "\n",
    "In the GA, after mating pairs are generated from a population, whether or not the crossover operation is employed is controlled by flipping a coin, biased according to the crossover probability $P_X$. If a random variate generated from $U\\left(0, 1\\right)$ is less than $P_X$, crossover is used. Otherwise, a mating pair produces a pair of offspring that are genetic replicants. Since crossover increases exploration of the objective function's solution space, I generally use a high probability - at least $P_X = 0.7$. I use three types of crossover.\n",
    "\n",
    "#### Single-Point\n",
    "In single-point crossover, a single crossover point (see what we did there?) is determined by generating a random value from $U\\left(1, n\\right)$. The two individuals in a mating pair have their chromosomes traded at that point, as shown in the illustration above.\n",
    "\n",
    "#### Dual-Point\n",
    "Dual-point crossover works similarly, except two crossover points are generated randomly in the same way as single-point crossover. The chromosomes are partitioned and traded at these points. This is shown in the illustration below, also from Thomas Hunt Morgan.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/4/45/Morgan_crossover_2.jpg' width='500' height='500'>\n",
    "\n",
    "#### Uniform\n",
    "Uniform crossover is the logical endpoint of the sequence of types of crossovers shown here. With uniform crossover, a random variate is generated from $U\\left(0, 1\\right)$ for each of the $n$ elements in the chromosomes being crossed over. For each element such that the random value is less than $P_X$, that element of the binary word is traded between the two individuals in the mating pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92cfbf-b233-4879-90c7-3348068d5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' single-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(42)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoint = 0\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoint = np.random.randint(1, n-1)\n",
    "        n1 = np.concatenate((p1[:xoverpoint], p2[xoverpoint:]))\n",
    "        n2 = np.concatenate((p2[:xoverpoint], p1[xoverpoint:]))\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=%d): %s <-> %s --> %s & %s'%(indx, xoverpoint, printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1e334-4d57-4620-830f-1a87cc089ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' dual-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(42)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoints = [0,0]\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoints = np.sort(np.random.permutation(n-1)[:2]+1)\n",
    "        n1 = np.concatenate((p1[:xoverpoints[0]], p2[xoverpoints[0]:xoverpoints[1]], p1[xoverpoints[1]:]))\n",
    "        n2 = np.concatenate((p2[:xoverpoints[0]], p1[xoverpoints[0]:xoverpoints[1]], p2[xoverpoints[1]:]))\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=[%d, %d]): %s <-> %s --> %s & %s'%(indx, xoverpoints[0], xoverpoints[1], printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0cae2-a810-41ef-95cc-0a46c3ff78b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' uniform-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(1211)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoint = [0]*n\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoints = probXover > np.random.rand(n)\n",
    "        n1 = p1*xoverpoints + p2*~xoverpoints\n",
    "        n2 = p1*~xoverpoints + p2*xoverpoints\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=%s): %s <-> %s --> %s & %s'%(indx, printIndiv(xoverpoints), printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f39fd-e4d7-4956-b2bc-2715d949aa72",
   "metadata": {},
   "source": [
    "### Mutation\n",
    "After mating pairs use crossover to generate a new population of individuals, the new individuals' chromosomes are mutated. Mutation simply entails flipping bits in the chromosome randomly, according to a small mutation probability $P_M$. To mutate an individual, $n$ random variates are generated from $U\\left(0, 1\\right)$. For any that are less than $P_M$, the corresponding bits are flipped. I generally use a low probability, such as $P_M=0.10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e5a3b-3f04-4478-b34d-c2cdd539828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' mutation '''\n",
    "# generate mutation flags\n",
    "probMutate = 0.1\n",
    "mutators = probMutate > np.random.rand(P, n)\n",
    "dat = pd.DataFrame(data = [printIndiv(m) for m in mutators], columns=['Mutate Flags'])\n",
    "\n",
    "# mutate\n",
    "dat['Before'] = [printIndiv(n) for n in newPop]\n",
    "newPop = newPop.copy()\n",
    "newPop[mutators] = ~(newPop[mutators])\n",
    "dat['After'] = [printIndiv(n) for n in newPop]\n",
    "\n",
    "# talk\n",
    "display(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9a31f-f592-499b-9304-c4725c389242",
   "metadata": {},
   "source": [
    "### GA Engineering\n",
    "One criticism of the GA is that, due to its stochastic nature, subsequent replications of the GA can end up with very different solutions to the same problem. This typically only occurs if a problem is very large and / or when the number of generations and population size are set too low. One solution is to employ an operator called *GA engineering*, which is intended to reduce variability between replications. Continuing the metaphor, GA engineering is akin to genetic engineering, in which genes from a more successful individual - such as a plant that is pest-resistant - is inserted into other individuals.\n",
    "\n",
    "GA engineering is employed after a new population has been created, when the best solution from the previous generation is better than the best solution of the current generation. The process takes the best individual from the previous and current generations, and finds the differences in their chromosomes; we'll call $\\Delta_{P-C}$ the bits that are on in the previous but not current best chromosome. $P$ random values are then generated from $U\\left(0, 1\\right)$; for individuals in the new population corresponding with a random variate being less than the probability of engineering $P_E$, the bits in $\\Delta_{P-C}$ are inserted. I usually set $P_M > P_E > P_X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4b21a-b49f-4fa9-a2a3-e99b16d25933",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GA engineering '''\n",
    "engineer_rate = 0.2\n",
    "# make a previous best\n",
    "prevBest = np.array([True, True, False,  True, True,  False, False, False, True, True])\n",
    "# get the difference\n",
    "currBest = population[np.argmax(fitness),:]\n",
    "diffLocs = np.logical_xor(currBest, prevBest)\n",
    "diffVals = prevBest[diffLocs]\n",
    "\n",
    "# print bests\n",
    "print('Previous Best: %s'%printIndiv(prevBest))\n",
    "print(' Current Best: %s'%printIndiv(currBest))\n",
    "\n",
    "# coin flips for implementing\n",
    "np.random.seed(42)\n",
    "engme = engineer_rate > np.random.rand(P)\n",
    "\n",
    "# engineer\n",
    "dat = pd.DataFrame({'Engineer':engme, 'Before':[printIndiv(m) for m in newPop]})\n",
    "newPopC = np.zeros((P, n), dtype=bool)\n",
    "rows = np.arange(P)\n",
    "# first build the output by adding the population elements that won't be changed\n",
    "rows_nochg = rows[~engme]\n",
    "newPopC[rows_nochg, :] = newPop[~engme, :]\n",
    "# now edit the rest of the population\n",
    "jnk = newPop[engme, :]\n",
    "jnk[:, diffLocs] = diffVals\n",
    "newPopC[rows[engme], :] = jnk\n",
    "newPop = newPopC\n",
    "dat['After'] = [printIndiv(m) for m in newPop]\n",
    "\n",
    "# talk\n",
    "display(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fd6ef-18e9-43f8-a4e8-15dd874242f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elitism\n",
    "In the GA, individuals in a generation generally die after mating, leaving the next generation all offspring. In real life, it can occasionally happen that an especially fit individual will remain a desirable mating partner for more than one generation; think Sean Connery, Harrison Ford, or Charlton Heston. This cross-generation interaction can be implemented as an option in the GA, with the *elitism* rule. When elitism is on the most fit solution from the current generation does not die, but joins the mating pool in the next generation. If there is already an individual in the next generation with the same chromosome, this has no effect.\n",
    "\n",
    "An advantage of elitism is that every generation always has the best individual in the population, so the GA's performance is monotonic. However, elitism means the population may grow with each generation. This can complicate mate ranking & selection, but is easily handled. Alternatively, we could design the GA to drop a random individual from the population before inserting the best individual, but this would hinder exploration of the solution space.\n",
    "\n",
    "Since elitism means that the best solution ever found by the GA is always in the mating pool, GA engineering is of limited value. I don't use both together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce80aa5-81e1-4925-92a9-c9f674442f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' elitism '''\n",
    "varis = np.arange(n) + 1\n",
    "bin_to_dec = 2**(varis - 1)\n",
    "    \n",
    "# check if best is currently in new_pop\n",
    "tmp1 = np.sum(newPop*bin_to_dec, axis=1)\n",
    "tmp2 = np.sum(currBest*bin_to_dec)\n",
    "\n",
    "if tmp2 not in tmp1:\n",
    "    population = np.vstack((newPop, currBest))\n",
    "    print('Elitism applied')\n",
    "    for (indx, individual) in enumerate(population):\n",
    "        print('%d: %s'%(indx, printIndiv(individual)))\n",
    "else:\n",
    "    population = newPop.copy()\n",
    "    print('Elitism not necessary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7130ae-e442-4372-b768-b03b5c93e53f",
   "metadata": {},
   "source": [
    "These steps are iterated over a specified number of generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f350a4-6e8a-473d-afd6-495c203c46e6",
   "metadata": {},
   "source": [
    "While the GA is not guaranteed to find the global optima, with appropriately-set parameters, it will most likely get very close. Indeed, the [no free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem) tells us that no optimization algorithm can outperform all others on all problems. Wolpert and Macready, who introduced the theorem stated \"*We have dubbed the associated results NFL theorems because they demonstrate that if an algorithm performs well on a certain class of problems then it necessarily pays for that with degraded performance on the set of all remaining problems.*\".\n",
    "\n",
    "Optimization problems have two jobs:\n",
    "- exploration: As compared to gradient-followers, or other otimization algorithms which consider solutions individually, population-based algorithms do a much better job of exploring the solution space. In the GA specifically, operators which can generate novel solutions such as mutation and crossover, help explore the solution space. A best solution which is near a local optimum may be a single bit's mutation away from the global optimum.\n",
    "\n",
    "- exploitation: The second job of an optimization algorithm is to more carefully explore promising areas of the solution space. This is something some gradient-following algorithms do well *when they are near the global optimum*. The BFGS algorithm is one. In the GA, GA engineering and the elitism rule help exploit good solutions, as they ensure useful elements of good chromosomes are not lost through mutation or crossover.\n",
    "\n",
    "In some cases, it may be beneficial for the GA to explore more in early generations, and exploit more in later generations. This could be implemented by setting a higher initial mutation rate, then allow the crossover and mutation probabilities to decay by generation. This is similar to the adaptive learning rate used by many optimizers for training deep learning neural networks. In simulated annealing, a decaying temperature parameter allows the algorithm to explore the solution space more thoroughly in earlier iterations. When the temperature is hot, the algorithm has a probability to make a move to a \"worse\" solution. As the temperture cools, the probability of a bad move approaches 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20741933-ddd5-4340-a11e-fc9778542797",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Applied\n",
    "We demonstrate use of the GA on three problems:\n",
    "\n",
    "- Feature Selection for Machine Learning\n",
    "- Best-fitting Distribution Selection\n",
    "- Multivariate Function Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c395b-bc94-4906-8b92-76cdaa6e4113",
   "metadata": {},
   "source": [
    "## Feature Selection for Machine Learning\n",
    "\n",
    "<a id=FSML></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "Statistical modelers have been trying models on subsets of features for almost as long as statistical modeling (most of what we call \"machine learning\" is actually statistical modeling) has been around. Perhaps unimaginably, we call the process of selecting a subset of available features feature selection. In feature selection, we use some procedure to generate subsets of the existing features, fit a model to them, and evaluate that model to find an optimal subset. The goal of feature selection is usually to balance two considerations: model performance and model complexity. It is generally beneficial for a model to be simpler - to use fewer features, for example. Practitioners often prefer a simpler model, even if it performs slightly worse than a more complex model. This follows the principle of [occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor).\n",
    "\n",
    "A simple way to perform feature selection, that guarantees finding the most optimal subset of features, is combinatorial enumeration - a.k.a. brute force. Combinatorial enumeration does exactly what it sounds like - the model is evauated on the enumeration of all possible combinations of features. This is no mean feat, as the number of ways to combine $p$ features is exponential in $p$; there are $2^{p-1}$ possible subsets. The GA is a useful tool for feature selection; for $p$ features, each individual is a p-length binary word indicating that a feature is in that solution (1) or out of it (0). If $p=8$, for example, one solution may be $10011001$; in this case, features 1,4,5,8 will be used, while 2,3,6,7 will not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc66da-2898-4833-b7e6-a89507cf12e2",
   "metadata": {},
   "source": [
    "The [GA Feature Selection Notebook](./GA_FeatureSelection.ipynb) demonstrates feature selection with the GA, using some data simulated with a known dependence structure. It begins with simulating $n=100$ observations of $p=20$ independent features, with each value drawn randomly from $U\\left(0, \\gamma=5\\right)$, so $X\\in\\mathcal{R}^{n\\times p}$. A target variable $y$ is then generated as\n",
    "\\begin{equation}\n",
    "y = 8X_0 - X_1 + 4X_2\n",
    "\\end{equation}\n",
    "Most of the features are uncorrelated with the target and each other, as shown in the [Feature Correlations Plot](https://github.com/ahowe42/FeatureCorrelationsPlot):\n",
    "\n",
    "<center><img src='../images/Correlations_8X0__1X1_4X2.png' height='1600'></center>\n",
    "\n",
    "With $p=20$ features, there are a total of $2^{20}-1=1,048,575$ possible subset regression models which can be fit to these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d587f5-a941-4400-9bcd-812a95628bd9",
   "metadata": {},
   "source": [
    "The GA was run with the inputs shown below, terminating early after around 90 generations, and evaluating only $25,828$ subsets of features - 2.5% of the total possible.\n",
    "\n",
    "<center><img src='../images/GAProgress_20220131161948_8X0__1X1_4X2_RegressionMetric.png' height='2000'></center>\n",
    "\n",
    "The top pane of the progress plot shows that the GA found the final solution in the 11$^{\\text{th}}$ generation - the solution includes the three correct features + only one additional feature. The annotation on the plot indicates the solution binary word, number features included, subset fitness score, and the score relative to the score of the saturated model (all features included). The bottom pane plots the average fitness score of all solutions per generation. Note that, even while the best solution was found in an early generation, the GA was still exploring the solution space quite well, as the average scores remained quite high relative to the best score, oscillating around 6.25 or so."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ebc5fe7-6849-48f5-ae50-fe8f9d16d07f",
   "metadata": {},
   "source": [
    "Executing GA 1 of 5\n",
    "Random Seed = 9271116\n",
    "##########################################\n",
    "GA Started on 2022-01-31T16:19:48.926073\n",
    "##########################################\n",
    "Data: 8X0+-1X1+4X2(n=100, p=20)\n",
    "Random Seed: 9271116\n",
    "Maximum # Generations: 100\n",
    "Mininum # of Generations: 80\n",
    "Convergence Criteria: 0.00001000\n",
    "Population Size: 200\n",
    "Initial Fill Percentage: 0.50\n",
    "Features Forced in all Models: None\n",
    "Initial Population Seeded with 0 Subsets\n",
    "Mutation Rate: 0.30\n",
    "Crossover Rate: 0.80\n",
    "Crossover Method: SINGLE\n",
    "Mating Method: ROULETTE\n",
    "Elitism is: ON\n",
    "!!With Elitism ON, the probability of GA engineering has been set to 0.00!!\n",
    "##########################################\n",
    "Objective: MINIMIZE\n",
    "Objective Function: RegressionMetric(metric='RMSE', estim=LinearRegression(fit_intercept=False), optimGoal=-1)\n",
    "##########################################\n",
    "Full Subset Score = 0.0000\n",
    "Generation 1 of 100: Best Score = 0.0000 (0.0457), Early Termination = 1\n",
    "\t11100111000010010111 (11)\n",
    "Generation 11 of 100: Best Score = 0.0000 (0.0224), Early Termination = 8\n",
    "\t11101100110000011011 (11)\n",
    "Generation 21 of 100: Best Score = 0.0000 (0.0151), Early Termination = 10\n",
    "\t11100100000000000000 (4)\n",
    "Generation 31 of 100: Best Score = 0.0000 (0.0151), Early Termination = 20\n",
    "\t11100100000000000000 (4)\n",
    "Generation 41 of 100: Best Score = 0.0000 (0.0151), Early Termination = 30\n",
    "\t11100100000000000000 (4)\n",
    "Generation 51 of 100: Best Score = 0.0000 (0.0151), Early Termination = 40\n",
    "\t11100100000000000000 (4)\n",
    "Generation 61 of 100: Best Score = 0.0000 (0.0151), Early Termination = 50\n",
    "\t11100100000000000000 (4)\n",
    "Generation 71 of 100: Best Score = 0.0000 (0.0151), Early Termination = 60\n",
    "\t11100100000000000000 (4)\n",
    "Generation 81 of 100: Best Score = 0.0000 (0.0151), Early Termination = 70\n",
    "\t11100100000000000000 (4)\n",
    "Early Termination On Generation 91 of 100\n",
    "Generation 91 of 100: Best Score = 0.0000 (0.0151), Early Termination = 80\n",
    "\t11100100000000000000 (4)\n",
    "##########################################\n",
    "GA Complete\n",
    "\tTotal Nontrivial Solutions Possible - 1048575\n",
    "\tUnique Subsets Evaluated - 25828 (2.46%)\n",
    "Full Subset Score = 0.0000\n",
    "Top 4 Solutions\n",
    "                        Score\tX0\tX1\tX2\tX3\tX4\tX5\tX6\tX7\tX8\tX9\tX10\tX11\tX12\tX13\tX14\tX15\tX16\tX17\tX18\tX19\t\t\tFrequency\tFull Relative\tSize\n",
    "11100100000000000000\t5.687290e-15\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.879121\t0.015066\t\t4.0\n",
    "11101100110000011011\t8.463395e-15\t1.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.087912\t0.022420\t\t11.0\n",
    "11110011110101010100\t9.906972e-15\t1.0\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t1.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t0.0\t0.021978\t0.026244\t\t12.0\n",
    "11100111000010010111\t1.724754e-14\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t0.0\t1.0\t0.0\t1.0\t1.0\t1.0\t0.010989\t0.045689\t\t11.0\n",
    "GA: Started on 2022-01-31T16:19:48.926073\n",
    "\tFinished on 2022-01-31T16:20:47.360854\n",
    "\tElapsed Time = 0.974(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347e926-867a-4544-9e15-f3b338042494",
   "metadata": {},
   "source": [
    "Finally, I generated four typical regression diagnostic plots based on the model residuals (from top left, clockwise):\n",
    "\n",
    "- target vs. predictions scatter plot - to assess how well the predictions match\n",
    "- histogram of residuals - to assess if the residuals appear to be Gaussian white noise centered on $0$\n",
    "- residuals ordered by data - to assess if there are any sequence-dependent patterns\n",
    "- residuals by target - to assess if the level of residuals shows a pattern vis-a-vis the level of target values\n",
    "\n",
    "<center><img src='../images/GAPerformance_20220131162231_8X0__1X1_4X2_RegressionMetric_metric__RMSE___estim_LinearRegression_fit_intercept_False___optimGoal__1.png' height='2000'></center>\n",
    "\n",
    "The plots show that the predicted values match the targets quite well, with very small errors that have no perceivable pattern.\n",
    "\n",
    "In conclusion, the GA did a good job of finding very close to the true [data generating process](https://en.wikipedia.org/wiki/Data_generating_process), settling on a set of features that included only a single extraneous feature. This performance is very satisfying, but recall that the data was generated with no additional noise. Adding noise would have changed the outcome, but this is likely an artifact of the simulation protocol, in that every feature was essentially white noise. This demonstration used a linear regression model, but other machine learning models could have been passed to the objective function. In fact, something completely different could have been used for the objective function. One good possibility could be some function of the mutual information among pairs of included features and the target variable. Finally, note that feature selection is particularly amenable to multi-objective optimization, in that we'd like to simultaneous find the best-fitting model, while penalizing for too much complexity. In this case, complexity could simply be measured by how many features are included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24265b-8209-4c14-ab21-f125b323cf94",
   "metadata": {},
   "source": [
    "## Best-fitting Distribution Selection\n",
    "\n",
    "<a id=BFDS></a>\n",
    "<a href=#top>Go to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d50669-ffe1-4c75-a959-9009e6fc1302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3a893-bffa-4c99-b997-95bd089b30e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c8d220-c2f1-4bb8-b7a8-7684501b7b7f",
   "metadata": {},
   "source": [
    "## Multivariate Function Minimization\n",
    "\n",
    "<a id=MFM></a>\n",
    "<a href=#top>Go to Top</a>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "901f39bb-4660-48bb-93a4-0e652d9bff73",
   "metadata": {},
   "source": [
    "note for later: could also see using complexity for distribution fitting, to compare GA runs with different distributions, to penalize for more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868931bb-8977-43ab-9625-2d68b9766304",
   "metadata": {},
   "source": [
    "<a href=#top>Go to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cabed7-efdc-4458-802b-e90d151cacb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
