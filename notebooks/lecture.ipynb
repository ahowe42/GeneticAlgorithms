{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0669b26f-da8b-4693-9c22-f8115aeb8864",
   "metadata": {},
   "source": [
    "# Genetic Algorithms\n",
    "## Evolutionary Algorithms for Optimization\n",
    "\n",
    "- <a href=#NGFA>Non-Gradent Following Optimization Algorithms</a>\n",
    "- <a href=#GA>Genetic Algorithm</a>\n",
    "- <a href=#FSML>Feature Selection for Machine Learning</a>\n",
    "- <a href=#BFDS>Best-fitting Distribution Selection</a>\n",
    "- <a href=#MFM>Multivariate Function Minimization</a>\n",
    "\n",
    "<a id=top></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e307aa7-917b-4423-9bdc-ab63b5ad6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stt\n",
    "import pandas as pd\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "# to use plotly offline, need to initialize with a plot\\n\",\n",
    "plyoff.init_notebook_mode(connected=True)\n",
    "init = go.Figure(data=[go.Scatter({'x':[1, 2], 'y':[42, 42], 'mode':'markers'})], layout=go.Layout(title='Init', xaxis={'title':'x'}, height=100, width=100))\n",
    "plyoff.iplot(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde10b3f-92df-45a2-b79e-2a6b5e27f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print binary strings\n",
    "printIndiv = lambda x: ''.join(['%d'%i for i in x])\n",
    "\n",
    "def EncodeBinaryReal(inputType, inputValue, bits, lowerBounds, upperBounds):\n",
    "    '''\n",
    "    Using a specified number of bits, and lower & upper real value bounds,\n",
    "    encode a list of real values as a list binary string, or a list binary\n",
    "    string as a list of real values.\n",
    "    :param inputType: 'r' = list of real values input; 'b' = list of\n",
    "        binary values\n",
    "    :param inputValue: either a list of n real values, or a single\n",
    "        list of the binary representation of n real value using the\n",
    "        number of bits indicated\n",
    "    :param bits: n-length array_like with number of bits used to encode\n",
    "        real values\n",
    "    :param lowerBounds: n-length array_like with lower bound of range\n",
    "        for real values\n",
    "    :param upperBounds: n-length array_like with upper bound of range\n",
    "        for real values\n",
    "    :return outVal: if inputType is 'r', n*sum(bits)-length list of binary\n",
    "        values; if inputType is 'b', n-length list of real values\n",
    "    '''\n",
    "    \n",
    "    if inputType == 'b': # binary in, so real out\n",
    "        # get the limits in the list of the individual values\n",
    "        binLims = [0]+np.cumsum(bits).tolist()\n",
    "        # iterate over binary strings\n",
    "        outVal = [0]*len(bits)\n",
    "        for indx, (low, hig, bt, lb, ub) in enumerate(zip(binLims[:-1],\n",
    "            binLims[1:], bits, lowerBounds, upperBounds)):\n",
    "            # get this real value's binary representation\n",
    "            binV = inputValue[low:hig]\n",
    "            # get the powers of 2 & max value\n",
    "            exps = [2**b for b in range(bt-1,-1, -1)]\n",
    "            mx = sum(exps)\n",
    "            # compute the real value\n",
    "            realV = sum([b*e for (b, e) in zip(binV, exps)])\n",
    "            realV = lb + (ub - lb)*realV/mx\n",
    "            outVal[indx] = realV\n",
    "    elif inputType == 'r': # real in, so binary out\n",
    "        # iterate over real values\n",
    "        reBinVal = [None]*len(inputValue)\n",
    "        for indx, (realV, bt, lb, ub) in enumerate(zip(inputValue, bits, lowerBounds, upperBounds)):\n",
    "            # stepsize in range\n",
    "            steps = (ub - lb)/(2**bt-1)\n",
    "            # values distance from lower\n",
    "            dist = int((realV - lb)/steps)\n",
    "            # encode the distance into binary\n",
    "            binV = [int(b) for b in bin(int(dist))[2:].zfill(bt)]\n",
    "            reBinVal[indx] = binV\n",
    "        outVal = list(chain.from_iterable(reBinVal))\n",
    "    else:\n",
    "        raise TypeError('Input type may only be \"b\" for \"r\"')\n",
    "    \n",
    "    return outVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ed8c3-0a04-464a-9e70-55c9f91125fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mathematical Optimization\n",
    "Optimization is the process of finding some numerical values that generate a minimum or maximum value for a specified function. Examples include finding the best parameters for a statistical distribution fit to some data, numerically solving differential equations, or feature selection in machine learning.\n",
    "\n",
    "There are many types and classes of optimization algorithms. Most that have been invented by mathematicianas and computer scientists rely on function derivatives / gradients. Anybody who's studied the topic even slightly will likely remember [Newton-Raphson](https://en.wikipedia.org/wiki/Newton%27s_method) or the [BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) - the latter of which even needs the second derivatives (the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)). Mathematical optimization algorithms typically iterate over two steps:\n",
    "\n",
    "1.  evaluate current solution\n",
    "2. find new solution to try\n",
    "\n",
    "A series of individual solutions are identified and evluated, until the sequence converges to a solution.\n",
    "\n",
    "Gradient-following methods can have good properties, but also two major issues.\n",
    "\n",
    "1. The first is the need to compute derivatives. This can often be very difficult - even assuming derivatives can be analytically solved - and time consuming. Furthermore, not all functions we wish to optimize even have a derivative. What is the derivative of an accuracy loss function for a [Decision Tree Classifier](https://en.wikipedia.org/wiki/Decision_tree_learning)?\n",
    "\n",
    "2. The second issue is that gradient-followers can easily get stuck in local optima, rather than finding a global optimum. Most such algorithms rely on being provided an initial value, at which value the necessary derivatives are computed to determine the direction (and perhaps distance) to find the next point to evaluate. Depending on the curvature of the function to optimize, and the initial value, the algorithm may get stuck in a local, not global, optimum.\n",
    "\n",
    "The figure generated below demonstrates this second point. The curve to be maximized has two optima with a saddle point in between. Four possible initial values are shown. When the curve's gradient is evaluated at the two $x_0$ points in red, an optimization algorithm will converge to the local optimum. The two in green will converge to the global optimum. In general, any initial value on the right side of the black vertical line will cause an optimization algorithm to converge to the global optimum; initial values to the left of it will converge to the local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b3508-3de3-43b0-a8f9-1b9fed5cb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "np.random.seed(42)\n",
    "X1 = stt.norm(loc=0, scale=1).rvs(500)\n",
    "X2 = stt.norm(loc=2, scale=0.5).rvs(500)\n",
    "data = np.r_[X1, X2]\n",
    "\n",
    "# prep for kde\n",
    "mn, mx = min(data), max(data)\n",
    "x= np.linspace(mn, mx, 200)\n",
    "\n",
    "# kde\n",
    "kde = stt.gaussian_kde(data, bw_method=0.25)\n",
    "y = kde(x)\n",
    "\n",
    "# create the annotation\n",
    "x1 = -1\n",
    "y1 = kde(x1)[0]\n",
    "ann1 = dict(x=x1, y=y1, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Local Optimum}$'%x1, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x2 = 0.40\n",
    "y2 = kde(x2)[0]\n",
    "ann2 = dict(x=x2, y=y2, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ←; Local Optimum}$'%x2, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x3 = 1.5\n",
    "y3 = kde(x3)[0]\n",
    "ann3 = dict(x=x3, y=y3, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Global Optimum}$'%x3, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x4 = 3.0\n",
    "y4 = kde(x4)[0]\n",
    "ann4 = dict(x=x4, y=y4, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ; Global Optimum}$'%x4, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x5 = 0.78698325\n",
    "y5 = kde(x5)[0]\n",
    "ann5 = dict(x=x5, y=y5, xref='x1', yref='y1', text='← Fails; Succeeds →', showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#6d72f1\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#636363\")\n",
    "\n",
    "# plot\n",
    "trcs = [go.Scatter(x=x, y=y, mode='lines', name='Kernel Density Estimate', showlegend=False),\n",
    "        go.Scatter(x=[x5, x5], y=[min(y), max(y)], mode='lines', line={'color':'black'}, showlegend=False)]\n",
    "fig = go.Figure(data=trcs, layout=go.Layout(title='Shortfall of Gradient Following', height=1000))\n",
    "anns = list(fig['layout']['annotations'])\n",
    "anns.extend([ann1, ann2, ann3, ann4, ann5])\n",
    "fig.update_layout( annotations=anns)\n",
    "#plyoff.plot(fig, include_mathjax='cdn')\n",
    "plyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3600b6c-f257-4268-8d85-0265dba18e9e",
   "metadata": {},
   "source": [
    "## Non-Gradent Following Optimization Algorithms\n",
    "<a id=NGFA></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "There are several types of mathematical optimization algorithms which similarly operate on a sequence of individual solutions, but don't use derivatives. I am familiar with [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing) and [Golden Section Search](https://en.wikipedia.org/wiki/Golden-section_search) opimization.\n",
    "\n",
    "There is an entirely different class of optimization algorithms which operate on ensembles of solutions - called a *population*, generally iteratively updating them in concert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb67cf5-2e9b-4f91-aadb-4b63a7afd19e",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithms\n",
    "The term [Evolutionary Algorithm (EA)](https://en.wikipedia.org/wiki/Evolutionary_algorithm) refers to a type of population-based metaheuristic optimization algorithm, and is a subset of evolutionary computation. Broadly, evolutionary algorithms are designed around concepts which come from biological evolution. There are several classes of evolutionary algorithms:\n",
    "\n",
    "- Differential Evolution\n",
    "- Evolutionary Programming\n",
    "- Evolutionary Strategy\n",
    "- Genetic Algorithm\n",
    "- Genetic Programming ([see here](https://github.com/ahowe42/baseball))\n",
    "- Learning Classifier System\n",
    "- Neuroevolution\n",
    "\n",
    "This set of lectures is focused on the Genetic Algorithm (GA), but could potentially be extended to include [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04162e2f-4de0-46aa-89a7-38967b81f865",
   "metadata": {},
   "source": [
    "## Other Gradient Eschewing Algorithms\n",
    "In addition to EA's, there are several other types of metaheuristic optimization algorithms that are based on the idea of optimizing with a population of potential solutions. These include:\n",
    "\n",
    "- [Ant Colony Optimization - or Traveling Ant Colony Optimization (TACO)](https://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms)\n",
    "- [Particle Swarm Optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization)\n",
    "- [Bees Algorithm](https://en.wikipedia.org/wiki/Bees_algorithm)\n",
    "- [Adaptive Dimensional Search](https://en.wikipedia.org/wiki/Adaptive_dimensional_search)\n",
    "- [Gaussian Adaptation](https://en.wikipedia.org/wiki/Gaussian_adaptation)\n",
    "- Harmony Search - special case of [Evolution Strategy](https://en.wikipedia.org/wiki/Evolution_strategy)\n",
    "\n",
    "I am only familiar with a few of these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d6212-27db-4924-afb6-d53ff1222ae1",
   "metadata": {},
   "source": [
    "## Genetic Algorithm\n",
    "<a id=GA></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "The genetic algorithm (GA) is a stochastic population-based metaheuristic optimization algorithm that borrows concepts from biological evolution. In the GA, a solution to an optimization problem is represented as a binary word of length $n$. In the GA parlance, this is metaphorically called an *individual*, or *chromosome*. Each solution is part of an ensemble of solutions which are considered together; this is called the *population*. The function to be optimized is called the *objective function*, or the *fitness function* - the latter is a metaphor to the biological concept of \"survival of the fittest\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d969ea-372a-4ab9-acd9-5d993f73f810",
   "metadata": {},
   "source": [
    "The semantic meaning of the binary word as a solution that optimizes an objective function (an individual being the most fit in it's environment) depends on the context. The binary word could represent selection flags for a feature selection problem; if instead the GA is being used to optimize a real-valued function, the word could be a digital representation of possible real values. In [this research article](https://www.researchgate.net/publication/301770005_Regularized_SVM_Classification_with_a_new_Complexity-Driven_Stochastic_Optimizer), I used the GA to simultaneously select a subset of features and one of 9 kernel functions for [kernel SVM classification](https://en.wikipedia.org/wiki/Support-vector_machine). The same binary word had one portion interpreted as binary flags, and the other portion as digital representations of the integers 1 to 9.\n",
    "\n",
    "To decode an $n$-length binary word $B$ into a real value $R$, the lower and upper bounds of the possible values, $L$ and $U$, must be provided. $R$ is then decoded from $B$ using the following steps:\n",
    "\\begin{align}\n",
    "pow =& [2^j]\\text{ for }j=0,1,\\ldots,n-1\\\\\n",
    "max =& \\sum_{j=0}^{n-1} pow_j\\\\\n",
    "steps =& \\sum_{j=0}^{n-1} pow_{j}\\times B_{j}\\\\\n",
    "R =& L + \\left(U-L\\right)\\frac{steps}{max}\n",
    "\\end{align}\n",
    "in the first step, $j$ iterates from the right to left, such that $pow$ is an $n$-length vector of integer powers of two. To instead encode $R$ into a binary word $B$, we compute:\n",
    "\\begin{align}\n",
    "steps =& \\frac{U - L}{2^n-1}\\\\\n",
    "dist = & \\frac{R - L}{steps}\n",
    "\\end{align}\n",
    "The value $dist$ is then cast to an integer and encoded using the computer's binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b26b63-9e1f-4b6a-9bbe-893982713884",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Real <-> Binary Encoding '''\n",
    "# setup real values to be binary encoded, demonstrating the effect of different range widths & different\n",
    "reals =  [42, 42, 42, 0, 100, 0, 100]\n",
    "lowers = [10, 30, 30, 0, 0, 0, 0]\n",
    "uppers = [74, 54, 54, 100, 100, 100, 100]\n",
    "bits =   [8, 8, 16, 8, 8, 16, 16]\n",
    "\n",
    "# encode & then decode\n",
    "B = EncodeBinaryReal('r', reals, bits, lowers, uppers)\n",
    "R = EncodeBinaryReal('b', B, bits, lowers, uppers)\n",
    "\n",
    "# parse B\n",
    "cumBits = np.cumsum([0]+bits)\n",
    "B = [printIndiv(B[f:t]) for (f, t) in zip(cumBits[:-1], cumBits[1:])]\n",
    "\n",
    "# show all in a dataframe\n",
    "display(pd.DataFrame(data=np.c_[[reals, lowers, uppers, bits, B, R]], index=['Input Real', 'Lower Bound', 'Upper Bound', 'Bits', 'Binary', 'Output Real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f50692-bc0b-48fb-9495-65bdfc379b78",
   "metadata": {},
   "source": [
    "The objective function is usually a map, $\\phi\\left(X\\in\\mathcal{R}^{m\\times p}, I^n\\right) \\rightarrow \\mathcal{R}$, jointly mapping some data plus a binary word to a scalar real value. GAs have also been developed for multi-objective optimization, in which case the objective function would map to a real-valued vector of length $q$: $\\phi\\left(X\\in\\mathcal{R}^{m\\times p}, I^n\\right) \\rightarrow \\mathcal{R}^q$. There are several approaches to this - I find approaches that use a [Pareto Front](https://en.wikipedia.org/wiki/Pareto_front) quite appealing.\n",
    "\n",
    "Almost all optimization algorithms need to start with an initial solution, and the same is true for the GA (and indeed, all Evolutionary Algorithms). For the GA, there may be domain knowledge-based ways to generate an initial population of $P$ individuals. However, it is common to initialize the population randomly, such that each bit has a 50% chance of being turned on.\n",
    "\n",
    "Starting from the initial population, the GA iterates over a few steps:\n",
    "\n",
    "1. score the fitness of each individual in the population\n",
    "2. rank and select individuals for mating\n",
    "3. mate pairs of individuals to create a new population\n",
    "\n",
    "    a. crossover\n",
    "    \n",
    "    b. mutation\n",
    "    \n",
    "    c. GA engineering\n",
    "4. apply any other GA operators\n",
    "\n",
    "Each population of individuals is called a *generation*. There are several ways to rank and select individuals for mating. There are also several operators that can be used in the GA, mostly related to creating a new generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce1b15-776a-4fc6-a15e-cc1cd5d7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate a sample population with scores '''\n",
    "# generate the population and scores\n",
    "n = 10\n",
    "P = 8\n",
    "np.random.seed(1906)\n",
    "population = np.random.rand(P, n) > 0.5\n",
    "fitness = np.random.rand(P)\n",
    "\n",
    "# sort\n",
    "stdIndex = np.argsort(fitness)[::-1]\n",
    "population = population[stdIndex]\n",
    "fitness = fitness[stdIndex]\n",
    "\n",
    "# talk\n",
    "print('Sample population with %d %d-length individuals'%(P,n))\n",
    "for indx, (score, individual) in enumerate(zip(fitness, population)):\n",
    "    print('%d: %s = %0.3f'%(indx, printIndiv(individual), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b1fa4-51b2-4a6b-a2c7-52853198aa4b",
   "metadata": {},
   "source": [
    "### Mating Ranking & Selection\n",
    "In the GA, mating is the process of combining two individuals to generate new individuals. I generally have two *parent* solutions mate to create a pair of *child* solutions. I do this is to keep a constant population size, but it's not required. For example, mating could choose to create, based on a randomized choice either:\n",
    "\n",
    "- a single offspring + new random individual\n",
    "- a pair of offspring\n",
    "\n",
    "The new random individual in the first option could be thought of as *adoption*, and would help explore the solution space. Note that I generally use an even population size, as it simplifies this step.\n",
    "\n",
    "If the GA is being run to optimize multiple objectives, this is the part of the algorithm that is most affected, as fitness scores are predominantly used to determine which individuals mate. I have generally used two approaches to mating ranking & selection - both of the below are more complicated for multi-objective problems.\n",
    "\n",
    "#### Sorted\n",
    "In biology, it is often the case that individuals that are similarly fit for their environment mate together (hence, the phrase \"she's out of my league\"). The metaphor generally holds for the GA, in that solutions with similar objective function scores are mated. This doesn't have to be the case. For example, we could mate pairs of solutions best-fitness to worst-fitness. This approach may help better explore the solution space, but I've never used it. \n",
    "\n",
    "The sorted approach to mate ranking and selection is simple, and has the property that each individual mates exactly and only one time. For this, all individuals are sorted according to their fitness scores, then paired off in sequence, so there are $P/2$ mating pairs generated.\n",
    "\n",
    "#### Roulette\n",
    "In biology, it is often the case that the most fit individuals mate the most, thus propagating their successful genes. This metaphor holds by design with the roulette method for generating mating pairs.\n",
    "\n",
    "The roulette method starts by sorting all individuals according to their fitness scores, then generating a biased roulette bar, in which the individual bins are of gradually decreasing size as computed and visualized (for $P=4$) here:\n",
    "\\begin{equation}\n",
    "b_i = \\frac{2i}{n\\left(n+1\\right)}, i=1,\\ldots,P\\text{.}\n",
    "\\end{equation}\n",
    "\n",
    "<center><img src='../images/roulette_selection.png' width='400' height='200'></center>\n",
    "\n",
    "When the cumulative sum of these bin widths is computed, we get upper bounds for the roulette bins, which completely partition the $[0, 1]$ interval. Each bin corresponds to an individual in the population; since the population was already sorted by fitness score, the wider bins correspond to the most fit individuals.\n",
    "\n",
    "Since we don't want the population to grow, we will generate $P/2$ mating pairs. To do so, $P$ random numbers are generated uniformly from $[0, 1]$ ($U\\left(0, 1\\right)$) and placed in the appropriate bin. For each random variate in the $i^\\text{th}$ bin, the corresponding individual will be selected to mate. In this way, individuals with a better fitness score are overrepresented in the mating pool. The last step is to randomly permute the ordering of the individuals in the mating pool.\n",
    "\n",
    "Note that this means that, while the most fit individuals will tend to mate the most frequently, they won't just mate with individuals with similar fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ac71e-7341-463f-8b48-57a3d0124710",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - sorted method '''\n",
    "# skipping sorting, as the population is already sorted\n",
    "pairs = np.reshape(range(P), (P//2, 2))\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26e359-8f05-4564-a0be-c386f0e996fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - roulette method '''\n",
    "# generate the bounds and show the bins\n",
    "binUBounds = np.cumsum(2*np.linspace(P, 1, P)/(P*(P + 1.0)))\n",
    "bnds = [0] + binUBounds.tolist()\n",
    "print('Roulette bins: %r'%[('%0.2f'%f, '%0.2f'%t) for f, t in zip(bnds[:-1], bnds[1:])])\n",
    "\n",
    "# generate mating frequencies\n",
    "np.random.seed(2022)\n",
    "rands_in_bins = np.repeat(np.random.rand(P), P) >= np.tile(binUBounds, P)\n",
    "pairs = np.reshape(np.random.permutation(np.sum(np.reshape(rands_in_bins, [P]*2), axis=1)), (P//2, 2))\n",
    "\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7ecdb-5f18-4300-82c9-dc3459bf445b",
   "metadata": {},
   "source": [
    "### Crossover\n",
    "In biology, when a pair of individuals mate, their chromosomes are combined in a process called [chromosomal crossover](https://en.wikipedia.org/wiki/Chromosomal_crossover). An illustration from 1916 by researcher Thomus Hunt Morgan demonstrates the creation of recombinant genes through this process.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/0/0e/Morgan_crossover_1.jpg' height='500' width='500'>\n",
    "\n",
    "In the GA, after mating pairs are generated from a population, whether or not the crossover operation is employed is controlled by flipping a coin, biased according to the crossover probability $P_X$. If a random variate generated from $U\\left(0, 1\\right)$ is less than $P_X$, crossover is used. Otherwise, a mating pair produces a pair of offspring that are genetic replicants. Since crossover increases exploration of the objective function's solution space, I generally use a high probability - at least $P_X = 0.7$. I use three types of crossover.\n",
    "\n",
    "#### Single-Point\n",
    "In single-point crossover, a single crossover point (see what I did there?) is determined by generating a random value from $U\\left(1, n\\right)$. The two individuals in a mating pair have their chromosomes traded at that point, as shown in the illustration above.\n",
    "\n",
    "#### Dual-Point\n",
    "Dual-point crossover works similarly, except two crossover points are generated randomly in the same way as single-point crossover. The chromosomes are partitioned and traded at these points. This is shown in the illustration below, also from Thomas Hunt Morgan.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/4/45/Morgan_crossover_2.jpg' width='500' height='500'>\n",
    "\n",
    "#### Uniform\n",
    "Uniform crossover is the logical endpoint of the sequence of types of crossovers shown here. With uniform crossover, a random variate is generated from $U\\left(0, 1\\right)$ for each of the $n$ elements in the chromosomes being crossed over. For each element such that the random value is less than $P_X$, that element of the binary word is traded between the two individuals in the mating pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92cfbf-b233-4879-90c7-3348068d5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' single-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(42)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoint = 0\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoint = np.random.randint(1, n-1)\n",
    "        n1 = np.concatenate((p1[:xoverpoint], p2[xoverpoint:]))\n",
    "        n2 = np.concatenate((p2[:xoverpoint], p1[xoverpoint:]))\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=%d): %s <-> %s --> %s & %s'%(indx, xoverpoint, printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1e334-4d57-4620-830f-1a87cc089ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' dual-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(42)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoints = [0,0]\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoints = np.sort(np.random.permutation(n-1)[:2]+1)\n",
    "        n1 = np.concatenate((p1[:xoverpoints[0]], p2[xoverpoints[0]:xoverpoints[1]], p1[xoverpoints[1]:]))\n",
    "        n2 = np.concatenate((p2[:xoverpoints[0]], p1[xoverpoints[0]:xoverpoints[1]], p2[xoverpoints[1]:]))\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=[%d, %d]): %s <-> %s --> %s & %s'%(indx, xoverpoints[0], xoverpoints[1], printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0cae2-a810-41ef-95cc-0a46c3ff78b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' uniform-point crossover '''\n",
    "# generate the crossover flags\n",
    "np.random.seed(1211)\n",
    "probXover = 0.7\n",
    "xovers = np.random.rand(len(pairs)) < probXover\n",
    "\n",
    "# crossover\n",
    "newPop = [None]*(2*len(pairs))\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    # get the individuals\n",
    "    p1 = population[pair[0]]\n",
    "    p2 = population[pair[1]]\n",
    "    if xovers[indx]:\n",
    "        # genetic replication\n",
    "        xoverpoint = [0]*n\n",
    "        n1, n2 = p1, p2\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    else:\n",
    "        # crossover\n",
    "        xoverpoints = probXover > np.random.rand(n)\n",
    "        n1 = p1*xoverpoints + p2*~xoverpoints\n",
    "        n2 = p1*~xoverpoints + p2*xoverpoints\n",
    "        newPop[indx*2] = n1\n",
    "        newPop[indx*2+1] = n2\n",
    "    # talk\n",
    "    print('Mating pair %d (xover=%s): %s <-> %s --> %s & %s'%(indx, printIndiv(xoverpoints), printIndiv(p1), printIndiv(p2), printIndiv(n1), printIndiv(n2)))\n",
    "newPop = np.array(newPop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f39fd-e4d7-4956-b2bc-2715d949aa72",
   "metadata": {},
   "source": [
    "### Mutation\n",
    "After mating pairs use crossover to generate a new population of individuals, the new individuals' chromosomes are mutated. Mutation simply entails flipping bits in the chromosome randomly, according to a small mutation probability $P_M$. To mutate an individual, $n$ random variates are generated from $U\\left(0, 1\\right)$. For any that are less than $P_M$, the corresponding bits are flipped. I generally use a low probability, such as $P_M=0.10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e5a3b-3f04-4478-b34d-c2cdd539828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' mutation '''\n",
    "# generate mutation flags\n",
    "probMutate = 0.1\n",
    "mutators = probMutate > np.random.rand(P, n)\n",
    "dat = pd.DataFrame(data = [printIndiv(m) for m in mutators], columns=['Mutate Flags'])\n",
    "\n",
    "# mutate\n",
    "dat['Before'] = [printIndiv(n) for n in newPop]\n",
    "newPop = newPop.copy()\n",
    "newPop[mutators] = ~(newPop[mutators])\n",
    "dat['After'] = [printIndiv(n) for n in newPop]\n",
    "\n",
    "# talk\n",
    "display(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9a31f-f592-499b-9304-c4725c389242",
   "metadata": {},
   "source": [
    "### GA Engineering\n",
    "One criticism of the GA is that, due to its stochastic nature, subsequent replications of the GA can end up with very different solutions to the same problem. This typically only occurs if a problem is very large and / or when the number of generations and population size are set too low. One solution is to employ an operator called *GA engineering*, which is intended to reduce variability between replications. Continuing the metaphor, GA engineering is akin to genetic engineering, in which genes from a more successful individual - such as a plant that is pest-resistant - is inserted into other individuals.\n",
    "\n",
    "GA engineering is employed after a new population has been created, when the best solution from the previous generation is better than the best solution of the current generation. The process takes the best individual from the previous and current generations, and finds the differences in their chromosomes; we'll call $\\Delta_{P-C}$ the bits that are on in the previous but not current best chromosome. $P$ random values are then generated from $U\\left(0, 1\\right)$; for individuals in the new population corresponding with a random variate being less than the probability of engineering $P_E$, the bits in $\\Delta_{P-C}$ are inserted. I usually set $P_M > P_E > P_X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4b21a-b49f-4fa9-a2a3-e99b16d25933",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GA engineering '''\n",
    "engineer_rate = 0.2\n",
    "# make a previous best\n",
    "prevBest = np.array([True, True, False,  True, True,  False, False, False, True, True])\n",
    "# get the difference\n",
    "currBest = population[np.argmax(fitness),:]\n",
    "diffLocs = np.logical_xor(currBest, prevBest)\n",
    "diffVals = prevBest[diffLocs]\n",
    "\n",
    "# print bests\n",
    "print('Previous Best: %s'%printIndiv(prevBest))\n",
    "print(' Current Best: %s'%printIndiv(currBest))\n",
    "\n",
    "# coin flips for implementing\n",
    "np.random.seed(42)\n",
    "engme = engineer_rate > np.random.rand(P)\n",
    "\n",
    "# engineer\n",
    "dat = pd.DataFrame({'Engineer':engme, 'Before':[printIndiv(m) for m in newPop]})\n",
    "newPopC = np.zeros((P, n), dtype=bool)\n",
    "rows = np.arange(P)\n",
    "# first build the output by adding the population elements that won't be changed\n",
    "rows_nochg = rows[~engme]\n",
    "newPopC[rows_nochg, :] = newPop[~engme, :]\n",
    "# now edit the rest of the population\n",
    "jnk = newPop[engme, :]\n",
    "jnk[:, diffLocs] = diffVals\n",
    "newPopC[rows[engme], :] = jnk\n",
    "newPop = newPopC\n",
    "dat['After'] = [printIndiv(m) for m in newPop]\n",
    "\n",
    "# talk\n",
    "display(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fd6ef-18e9-43f8-a4e8-15dd874242f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elitism\n",
    "In the GA, individuals in a generation generally die after mating, leaving the next generation all offspring. In real life, it can occasionally happen that an especially fit individual will remain a desirable mating partner for more than one generation; think Sean Connery, Harrison Ford, or Charlton Heston. This cross-generation interaction can be implemented as an option in the GA, with the *elitism* rule. When elitism is on the most fit solution from the current generation does not die, but joins the mating pool in the next generation. If there is already an individual in the next generation with the same chromosome, this has no effect.\n",
    "\n",
    "An advantage of elitism is that every generation always has the best individual in the population, so the GA's performance is monotonic. However, elitism means the population may grow with each generation. This can complicate mate ranking & selection, but is easily handled. Alternatively, we could design the GA to drop a random individual from the population before inserting the best individual, but this would hinder exploration of the solution space.\n",
    "\n",
    "Since elitism means that the best solution ever found by the GA is always in the mating pool, GA engineering is of limited value. I don't use both together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce80aa5-81e1-4925-92a9-c9f674442f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' elitism '''\n",
    "varis = np.arange(n) + 1\n",
    "bin_to_dec = 2**(varis - 1)\n",
    "    \n",
    "# check if best is currently in new_pop\n",
    "tmp1 = np.sum(newPop*bin_to_dec, axis=1)\n",
    "tmp2 = np.sum(currBest*bin_to_dec)\n",
    "\n",
    "if tmp2 not in tmp1:\n",
    "    population = np.vstack((newPop, currBest))\n",
    "    print('Elitism applied')\n",
    "    for (indx, individual) in enumerate(population):\n",
    "        print('%d: %s'%(indx, printIndiv(individual)))\n",
    "else:\n",
    "    population = newPop.copy()\n",
    "    print('Elitism not necessary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7130ae-e442-4372-b768-b03b5c93e53f",
   "metadata": {},
   "source": [
    "These steps are iterated over a specified number of generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f350a4-6e8a-473d-afd6-495c203c46e6",
   "metadata": {},
   "source": [
    "While the GA is not guaranteed to find the global optima, with appropriately-set parameters, it will most likely get very close. Indeed, the [no free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem) tells us that no optimization algorithm can outperform all others on all problems. Wolpert and Macready, who introduced the theorem stated \"*We have dubbed the associated results NFL theorems because they demonstrate that if an algorithm performs well on a certain class of problems then it necessarily pays for that with degraded performance on the set of all remaining problems.*\".\n",
    "\n",
    "Optimization problems have two jobs:\n",
    "- exploration: As compared to gradient-followers, or other otimization algorithms which consider solutions individually, population-based algorithms do a much better job of exploring the solution space. In the GA specifically, operators which can generate novel solutions such as mutation and crossover, help explore the solution space. A best solution which is near a local optimum may be a single bit's mutation away from the global optimum.\n",
    "\n",
    "- exploitation: The second job of an optimization algorithm is to more carefully explore promising areas of the solution space. This is something some gradient-following algorithms do well *when they are near the global optimum*. The BFGS algorithm is one. In the GA, GA engineering and the elitism rule help exploit good solutions, as they ensure useful elements of good chromosomes are not lost through mutation or crossover.\n",
    "\n",
    "In some cases, it may be beneficial for the GA to explore more in early generations, and exploit more in later generations. This could be implemented by setting a higher initial mutation rate, then allow the crossover and mutation probabilities to decay by generation. This is similar to the adaptive learning rate used by many optimizers for training deep learning neural networks. In simulated annealing, a decaying temperature parameter allows the algorithm to explore the solution space more thoroughly in earlier iterations. When the temperature is hot, the algorithm has a probability to make a move to a \"worse\" solution. As the temperture cools, the probability of a bad move approaches 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734dd0f-accd-45a8-9b77-ce60143568b6",
   "metadata": {},
   "source": [
    "### Other GA Parameters\n",
    "There are various other parameters that I often add to how the genetic algorithm runs.\n",
    "\n",
    "#### Initial Percentage\n",
    "As stated earlier, it is common to initialize the population randomly, such that each bit has a 50% chance of being turned on, but this isn't necessary. I often specify an *initial percentage* parameter, which specifies what percentage of all bits in the initial population should be flipped on.\n",
    "\n",
    "#### Premature Termination\n",
    "If the GA has settled on a solution which doesn't get improved over many generations, there may be no value to continuing the algorithm - especially if compututation is expensive. To handle this, the GA can accept additional parameters\n",
    "\n",
    "- *no change terminate* - number of generations $T$\n",
    "- *convergence criteria* - minimal change between generations $\\Delta_\\min$\n",
    "\n",
    "If $T$ generations pass with $\\Delta\\left(\\text{generation_best_score} - \\text{best_score}\\right) <= \\Delta_\\min$, the algorithm terminates prematurely.\n",
    "\n",
    "#### Seed Solutions\n",
    "In addition to randomly initializing the population, there can sometimes be value in including specific solutions - *seed solutions* - in the initial population. This would usually be used to add some domain knowledge into how the GA runs. I have only ever used it when the GA is used for feature selection. For example, it could be useful for the initial population to start with solutions encoding only singleton feature subsets.\n",
    "\n",
    "#### Replications\n",
    "We call each time we run the genetic algorithm for a specific problem a *replication*. Because of how it explores the solution space, the GA will generally converge to a near-global solution. However, it is a stochastic search algorithm, so it is possible that different replications may result in different solutions, depending on the parameters. Besides using better parameters - which may not always be the cause of this variability, or even possible - we can run multiple replications, and take the best of the best solutions among all replications as the final best solution. A good use of seeding solutions is to have the best solution from a replication seeded into the initial population of the next replication. The feature selection for machine learning notebook does this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20741933-ddd5-4340-a11e-fc9778542797",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Applied\n",
    "I demonstrate use of the GA on three problems:\n",
    "\n",
    "- Feature Selection for Machine Learning\n",
    "- Best-fitting Distribution Selection\n",
    "- Multivariate Function Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c395b-bc94-4906-8b92-76cdaa6e4113",
   "metadata": {},
   "source": [
    "## Feature Selection for Machine Learning\n",
    "\n",
    "<a id=FSML></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "Statistical modelers have been trying models on subsets of features for almost as long as statistical modeling (most of what we call \"machine learning\" is actually statistical modeling) has been around. Perhaps unimaginably, we call the process of selecting a subset of available features [feature selection](https://en.wikipedia.org/wiki/Feature_selection). In feature selection, we use some procedure to generate subsets of the existing features, fit a model to them, and evaluate that model to find an optimal subset. The goal of feature selection is usually to balance two considerations: model performance and model complexity. It is generally beneficial for a model to be simpler - to use fewer features, for example. Practitioners often prefer a simpler model, even if it performs slightly worse than a more complex model. This follows the principle of [Occam's Razor](https://en.wikipedia.org/wiki/Occam%27s_razor).\n",
    "\n",
    "A simple way to perform feature selection, that guarantees finding the most optimal subset of features, is combinatorial enumeration - a.k.a. brute force. Combinatorial enumeration does exactly what it sounds like - the model is evauated on the enumeration of all possible combinations of features. This is no mean feat, as the number of ways to combine $p$ features is exponential in $p$; there are $2^{p-1}$ possible subsets. The GA is a useful tool for feature selection; for $p$ features, each individual is a p-length binary word indicating that a feature is in that solution (1) or out of it (0). If $p=8$, for example, one solution may be $10011001$; in this case, features 1,4,5,8 will be used, while 2,3,6,7 will not.\n",
    "\n",
    "The [GA Feature Selection Notebook](./GA_FeatureSelection.ipynb) demonstrates feature selection with the GA for a given dataset with the goal of minimzing error from a machine learning model. The data is simulated using a known dependence structure, so it is possible to assess the accuracy of the GA result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc66da-2898-4833-b7e6-a89507cf12e2",
   "metadata": {},
   "source": [
    "I begin by simulating $n=100$ observations of $p=20$ independent features, with each value drawn randomly from $U\\left(0, \\gamma=5\\right)$, so $X\\in\\mathcal{R}^{n\\times p}$. A target variable $y$ is then generated as\n",
    "\\begin{equation}\n",
    "y = 8X_0 - X_1 + 4X_2\n",
    "\\end{equation}\n",
    "Most of the features are uncorrelated with the target and each other, as shown in the [Feature Correlations Plot](https://github.com/ahowe42/FeatureCorrelationsPlot):\n",
    "\n",
    "<center><img src='../images/Correlations_8X0__1X1_4X2.png' height='1600'></center>\n",
    "\n",
    "With $p=20$ features, there are a total of $2^{20}-1=1,048,575$ possible subset regression models which can be fit to these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d587f5-a941-4400-9bcd-812a95628bd9",
   "metadata": {},
   "source": [
    "The GA was run with the inputs shown below, terminating early after around 90 generations, and evaluating only $25,828$ subsets of features - 2.5% of the total possible.\n",
    "\n",
    "<center><img src='../images/GAProgress_20220131161948_8X0__1X1_4X2_RegressionMetric.png' height='2000'></center>\n",
    "\n",
    "The top pane of the progress plot shows that the GA found the final solution in the 11$^{\\text{th}}$ generation - the solution includes the three correct features + only one additional feature. The annotation on the plot indicates the solution binary word, number features included, subset fitness score, and the score relative to the score of the saturated model (all features included). The bottom pane plots the average fitness score of all solutions per generation. Note that, even while the best solution was found in an early generation, the GA was still exploring the solution space quite well, as the average scores remained quite high relative to the best score, oscillating around 6.25 or so."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ebc5fe7-6849-48f5-ae50-fe8f9d16d07f",
   "metadata": {},
   "source": [
    "Executing GA 1 of 5\n",
    "Random Seed = 9271116\n",
    "##########################################\n",
    "GA Started on 2022-01-31T16:19:48.926073\n",
    "##########################################\n",
    "Data: 8X0+-1X1+4X2(n=100, p=20)\n",
    "Random Seed: 9271116\n",
    "Maximum # Generations: 100\n",
    "Mininum # of Generations: 80\n",
    "Convergence Criteria: 0.00001000\n",
    "Population Size: 200\n",
    "Initial Fill Percentage: 0.50\n",
    "Features Forced in all Models: None\n",
    "Initial Population Seeded with 0 Subsets\n",
    "Mutation Rate: 0.30\n",
    "Crossover Rate: 0.80\n",
    "Crossover Method: SINGLE\n",
    "Mating Method: ROULETTE\n",
    "Elitism is: ON\n",
    "!!With Elitism ON, the probability of GA engineering has been set to 0.00!!\n",
    "##########################################\n",
    "Objective: MINIMIZE\n",
    "Objective Function: RegressionMetric(metric='RMSE', estim=LinearRegression(fit_intercept=False), optimGoal=-1)\n",
    "##########################################\n",
    "Full Subset Score = 0.0000\n",
    "Generation 1 of 100: Best Score = 0.0000 (0.0457), Early Termination = 1\n",
    "\t11100111000010010111 (11)\n",
    "Generation 11 of 100: Best Score = 0.0000 (0.0224), Early Termination = 8\n",
    "\t11101100110000011011 (11)\n",
    "Generation 21 of 100: Best Score = 0.0000 (0.0151), Early Termination = 10\n",
    "\t11100100000000000000 (4)\n",
    "Generation 31 of 100: Best Score = 0.0000 (0.0151), Early Termination = 20\n",
    "\t11100100000000000000 (4)\n",
    "Generation 41 of 100: Best Score = 0.0000 (0.0151), Early Termination = 30\n",
    "\t11100100000000000000 (4)\n",
    "Generation 51 of 100: Best Score = 0.0000 (0.0151), Early Termination = 40\n",
    "\t11100100000000000000 (4)\n",
    "Generation 61 of 100: Best Score = 0.0000 (0.0151), Early Termination = 50\n",
    "\t11100100000000000000 (4)\n",
    "Generation 71 of 100: Best Score = 0.0000 (0.0151), Early Termination = 60\n",
    "\t11100100000000000000 (4)\n",
    "Generation 81 of 100: Best Score = 0.0000 (0.0151), Early Termination = 70\n",
    "\t11100100000000000000 (4)\n",
    "Early Termination On Generation 91 of 100\n",
    "Generation 91 of 100: Best Score = 0.0000 (0.0151), Early Termination = 80\n",
    "\t11100100000000000000 (4)\n",
    "##########################################\n",
    "GA Complete\n",
    "\tTotal Nontrivial Solutions Possible - 1048575\n",
    "\tUnique Subsets Evaluated - 25828 (2.46%)\n",
    "Full Subset Score = 0.0000\n",
    "Top 4 Solutions\n",
    "                        Score\tX0\tX1\tX2\tX3\tX4\tX5\tX6\tX7\tX8\tX9\tX10\tX11\tX12\tX13\tX14\tX15\tX16\tX17\tX18\tX19\t\t\tFrequency\tFull Relative\tSize\n",
    "11100100000000000000\t5.687290e-15\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.879121\t0.015066\t\t4.0\n",
    "11101100110000011011\t8.463395e-15\t1.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.087912\t0.022420\t\t11.0\n",
    "11110011110101010100\t9.906972e-15\t1.0\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t1.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t0.0\t0.021978\t0.026244\t\t12.0\n",
    "11100111000010010111\t1.724754e-14\t1.0\t1.0\t1.0\t0.0\t0.0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t0.0\t1.0\t0.0\t1.0\t1.0\t1.0\t0.010989\t0.045689\t\t11.0\n",
    "GA: Started on 2022-01-31T16:19:48.926073\n",
    "\tFinished on 2022-01-31T16:20:47.360854\n",
    "\tElapsed Time = 0.974(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347e926-867a-4544-9e15-f3b338042494",
   "metadata": {},
   "source": [
    "Finally, I generated four typical regression diagnostic plots based on the model residuals (from top left, clockwise):\n",
    "\n",
    "- target vs. predictions scatter plot - to assess how well the predictions match\n",
    "- histogram of residuals - to assess if the residuals appear to be Gaussian white noise centered on $0$\n",
    "- residuals ordered by data - to assess if there are any sequence-dependent patterns\n",
    "- residuals by target - to assess if the level of residuals shows a pattern vis-a-vis the level of target values\n",
    "\n",
    "<center><img src='../images/GAPerformance_20220131162231_8X0__1X1_4X2_RegressionMetric_metric__RMSE___estim_LinearRegression_fit_intercept_False___optimGoal__1.png' height='2000'></center>\n",
    "\n",
    "The plots show that the predicted values match the targets quite well, with very small errors that have no perceivable pattern.\n",
    "\n",
    "In conclusion, the GA did a good job of finding very close to the true [data generating process](https://en.wikipedia.org/wiki/Data_generating_process), settling on a set of features that included only a single extraneous feature. This performance is very satisfying, but recall that the data was generated with no additional noise. Adding noise would have changed the outcome, but this is likely an artifact of the simulation protocol, in that every feature was essentially white noise. This demonstration used a linear regression model, but other machine learning models could have been passed to the objective function. In fact, something completely different could have been used for the objective function. One good possibility could be some function of the mutual information among pairs of included features and the target variable. Finally, note that feature selection is particularly amenable to multi-objective optimization, in that we'd like to simultaneous find the best-fitting model, while penalizing for too much complexity. In this case, complexity could simply be measured by how many features are included, or perhaps something even more (wait for it) complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24265b-8209-4c14-ab21-f125b323cf94",
   "metadata": {},
   "source": [
    "## Best-fitting Distribution Selection\n",
    "\n",
    "<a id=BFDS></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "There are three major perceptions of data in statistics:\n",
    "- [Frequentist](https://en.wikipedia.org/wiki/Frequentist_inference) - considers observed data to be a random sample from an unknown population generated by a \"real\" probability distribution\n",
    "- [Bayesian](https://en.wikipedia.org/wiki/Bayesian_inference) - considers observed data to be \"real\", which can be represented by a probability distribution\n",
    "- [Information Theoretic](https://en.wikipedia.org/wiki/Information_theory) - focuses on determining the maximal amount of information in (or that can be gleaned from) some data\n",
    "\n",
    "The Frequentist perspective underlies the majority of statistical thinking used, and gives us hypothesis testing and confidence intervals. An exercise commonly performed in statistics - whether Frequentist of Bayesian - is that of determining a statistical probability distribution $f\\left(X\\vert\\theta\\right)$ which fits a dataset $X$ best, given a vector of parameters $\\theta$ (the length of which depends on $f$). Frequentists will pick the distribution and it's parameters by maximizing the likelihood function $l\\left(\\theta\\vert X\\right)$, or the log likelihood $\\log l\\left(\\theta\\vert X\\right)$ instead:\n",
    "\\begin{align}\n",
    "l\\left(\\theta\\vert X\\right) =& \\prod_i^{n}f\\left(X\\vert\\theta\\right)\\\\\n",
    "\\log l\\left(\\theta\\vert X\\right) =& \\sum_i^{n}\\log\\big(f\\left(X\\vert\\theta\\right)\\big)\n",
    "\\end{align}\n",
    "Note that the log likelihood is the sum of the log of the probability densities for each observed datapoint, given parameters $\\theta$. The [maximum likelihood estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation), or MLE $\\hat{\\theta}$, is the parameter vector which has the highest probability of generating the sample data observed. Instead of finding the parameters which maximize the log likelihood, Bayesians will use the [highest posterior density interval (or credibility interval)](https://en.wikipedia.org/wiki/Credible_interval). MLE's for some statistical distributions, such as the Gaussian, can be found analytically, computed as a function of the observed sample data. For example, the univariate Gaussian distribution and the MLE's of it's parameters $\\mu$ and $\\sigma$ are:\n",
    "\\begin{align}\n",
    "f\\left(x_i\\vert\\mu,\\sigma\\right) =& \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^2}\\\\\n",
    "\\hat{\\mu} =& \\bar{X} = \\frac{1}{n}\\sum_{i=1}^n x_i\\\\\n",
    "\\hat{\\sigma} = & S = \\frac{1}{n-1}\\sum_{i=1}^n \\left(x_i-\\bar{X}\\right)^2\n",
    "\\end{align}\n",
    "\n",
    "For most other probability distributions, the likelihood function must be numerically optimized. If the MLE for a distribution $f$ fit to a dataset $X$ gives the parameters most likely to have generated the observed sample data, then we can pick the distribution $\\hat{f}$ most likely to have generated the sample data by as the distribution associated with the maximum likelihood evaluated at the MLE's:\n",
    "\\begin{equation}\n",
    "\\hat{f} = \\underset{j}{argmax}\\big[\\log l_j\\left(\\hat{\\theta}_j\\vert X\\right)\\big]\\text{, for }\\big[j\\in\\text{set of distributions}\\big].\n",
    "\\end{equation}\n",
    "\n",
    "To use the GA to find the MLE's for a distribution with $n$ parameters, each binary word on which the GA operates should be of length $\\sum_{i=1}^nq_i$, with the $i^\\text{th}$ parameter being encoded in $q_i$ bits. There is no requirement for $q_i = q_j$.\n",
    "\n",
    "The [GA Real Optimization - Statistical Distribution Fitting](./GA_RealOptimization_DistFit.ipynb) demonstrates using the GA to find the best fitting distribution for a given dataset. The data is simulated from a distribution with known parameters, so it is possible to assess the accuracy of the GA result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccf8b5-cfef-4a36-853e-0a0a787e78eb",
   "metadata": {},
   "source": [
    "While the notebook allows the sample data to be generated from any of the distributions below - plus the lognormal and uniform - I begin by generating $n=100$ random observations from a Gaussian distribution, with $\\mu=42$ and $\\sigma=1$. The set of probability distributions for evaluation are the following.\n",
    "- Gaussian\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\mu,\\sigma\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^2}\n",
    "\\end{equation}\n",
    "- Gamma\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\mu,\\alpha,\\beta\\right) = \\frac{\\beta^\\alpha\\left(x_i-\\mu\\right)^{\\alpha-1}e^{-\\beta\\left(x_i-\\mu\\right)}}{\\Gamma\\left(\\alpha\\right)}\n",
    "\\end{equation}\n",
    "- Exponential\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\lambda\\right) = \\lambda e^{-\\lambda x}\n",
    "\\end{equation}\n",
    "- Chi-squared\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\kappa\\right) = \\frac{x_i^{\\frac{\\kappa}{2}-1}e^{-\\frac{x_i}{2}}}{2^\\frac{\\kappa}{2}\\Gamma\\left(\\frac{\\kappa}{2}\\right)}\n",
    "\\end{equation}\n",
    "- Student's t\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\nu\\right) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\pi\\nu}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1+\\frac{x_i^2}{\\nu}\\right)^{-\\frac{\\left(\\nu+1\\right)}{2}}\n",
    "\\end{equation}\n",
    "- Cauchy\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\mu\\right) = \\frac{1}{\\pi\\left(1+\\left(x_i-\\mu\\right)^2\\right)}\n",
    "\\end{equation}\n",
    "- Laplace\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\mu,\\sigma\\right) = \\frac{1}{2}e^{-\\left\\vert \\frac{x_i-\\mu}{\\sigma}\\right\\vert}\n",
    "\\end{equation}\n",
    "- Pareto\n",
    "\\begin{equation}\n",
    "f\\left(x\\vert\\beta\\right) = \\frac{\\beta}{x_i^{\\beta+1}}\n",
    "\\end{equation}\n",
    "\n",
    "The `PDFParamRanges()` function in the Utils.py file returns, for a given dataset and specified distribution, the range in which each parameter is likely to be found. For some parameters, the ranges come from asymptotic properties of MLE's, whereas others are based on method-of-moments estimators. The only exceptions are the gamma and Pareto distributions, for which I use the [fit method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html) of scipy's distribution object, and make a symmetric range around it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001deb84-2e8b-4619-bc68-862b852d4ed5",
   "metadata": {},
   "source": [
    "To simultaneously find the best-fitting distribution and get the best parameters, I execute two replications of the GA for each of the above 8 distributions. When running the GA, I use $q=16$ bits to encode each parameter into a binary word. Hence, each binary word will be 16 bits long when fitting the Pareto distribution, but will be 48 bits when fitting the gamma distribution, for example.\n",
    "\n",
    "The GA was run with the inputs shown below, varying only the distribution and encoding ranges. For fitting the Gaussian distribution, out of a total of 4,294,967,296 possible solutions, only 59,403 were evaluated.\n",
    "\n",
    "<center><img src='../images/GAProgress_20220203172408_NRM_42__1__ComputeLikelihood_dist__NRM.png' height='2000'></center>\n",
    "\n",
    "For fitting the Gaussian distribution, the GA found it's final solution - quite close to the true values - before a quarter of the planned generations were executed. Despite this, the average fitness score over each generation continued to vary, indicating exploration of the solution space."
   ]
  },
  {
   "cell_type": "raw",
   "id": "242e96e3-f132-40a6-a1ae-1f9a282fa2ae",
   "metadata": {},
   "source": [
    "Executing GA for NRM Distribution\n",
    "Executing GA 1 of 2\n",
    "Random Seed = 7188349\n",
    "##########################################\n",
    "GA Started on 2022-02-03T17:24:08.717837\n",
    "##########################################\n",
    "Data: NRM(42, 1)(n=2)\n",
    "Random Seed: 7188349\n",
    "Maximum # Generations: 100\n",
    "Mininum # of Generations: 80\n",
    "Convergence Criteria: 0.00001000\n",
    "Population Size: 200\n",
    "Initial Fill Percentage: 0.50\n",
    "Mutation Rate: 0.30\n",
    "Crossover Rate: 0.80\n",
    "Crossover Method: SINGLE\n",
    "Mating Method: ROULETTE\n",
    "Elitism is: ON\n",
    "!!With Elitism ON, the probability of GA engineering has been set to 0.00!!\n",
    "##########################################\n",
    "Objective: MAXIMIZE\n",
    "Objective Function: ComputeLikelihood(dist='NRM')\n",
    "Bit Encoding:\n",
    "Real00\tReal01\n",
    "Bits\t16.000000\t16.000000\n",
    "Lower\t41.625069\t0.000100\n",
    "Upper\t42.167238\t1.355424\n",
    "##########################################\n",
    "Generation 1 of 100: Best Score = -131.9051, Early Termination = 1\n",
    "\t[41.8815,0.9378]\n",
    "../src\\GA\\Objective.py:129: RuntimeWarning:\n",
    "\n",
    "divide by zero encountered in log\n",
    "\n",
    "Generation 11 of 100: Best Score = -131.7649, Early Termination = 1\n",
    "\t[41.9012,0.9098]\n",
    "Generation 21 of 100: Best Score = -131.7609, Early Termination = 1\n",
    "\t[41.8960,0.9078]\n",
    "Generation 31 of 100: Best Score = -131.7598, Early Termination = 3\n",
    "\t[41.8955,0.9065]\n",
    "Generation 41 of 100: Best Score = -131.7598, Early Termination = 13\n",
    "\t[41.8955,0.9065]\n",
    "Generation 51 of 100: Best Score = -131.7598, Early Termination = 23\n",
    "\t[41.8955,0.9065]\n",
    "Generation 61 of 100: Best Score = -131.7598, Early Termination = 33\n",
    "\t[41.8955,0.9065]\n",
    "Generation 71 of 100: Best Score = -131.7595, Early Termination = 5\n",
    "\t[41.8959,0.9060]\n",
    "Generation 81 of 100: Best Score = -131.7595, Early Termination = 15\n",
    "\t[41.8959,0.9060]\n",
    "Generation 91 of 100: Best Score = -131.7595, Early Termination = 5\n",
    "\t[41.8955,0.9060]\n",
    "Generation 100 of 100: Best Score = -131.7595, Early Termination = 14\n",
    "\t[41.8955,0.9060]\n",
    "##########################################\n",
    "GA Complete\n",
    "\tUnique Solutions Evaluated - 29701\n",
    "\tTotal Solutions Possible - 4294967296\n",
    "Top 10 Solutions\n",
    "Score\tReal00\tReal01\tFrequency\n",
    "[41.8955,0.9060]\t-131.759506\t41.895496\t0.905986\t0.14\n",
    "[41.8959,0.9060]\t-131.759507\t41.895901\t0.906028\t0.20\n",
    "[41.8955,0.9065]\t-131.759825\t41.895454\t0.906483\t0.38\n",
    "[41.8960,0.9078]\t-131.760930\t41.895967\t0.907806\t0.08\n",
    "[41.9012,0.9098]\t-131.764912\t41.901188\t0.909771\t0.10\n",
    "[41.8848,0.8921]\t-131.783458\t41.884757\t0.892130\t0.01\n",
    "[41.9078,0.8906]\t-131.788700\t41.907773\t0.890558\t0.02\n",
    "[41.9200,0.9073]\t-131.794984\t41.920009\t0.907269\t0.01\n",
    "[41.9210,0.8967]\t-131.802892\t41.920952\t0.896742\t0.04\n",
    "[41.9090,0.9293]\t-131.845450\t41.909022\t0.929294\t0.01\n",
    "GA: Started on 2022-02-03T17:24:08.717837\n",
    "\tFinished on 2022-02-03T17:24:22.049455\n",
    "\tElapsed Time = 0.222(m)\n",
    "Executing GA 2 of 2\n",
    "Random Seed = 49456\n",
    "##########################################\n",
    "GA Started on 2022-02-03T17:24:22.049455\n",
    "##########################################\n",
    "Data: NRM(42, 1)(n=2)\n",
    "Random Seed: 49456\n",
    "Maximum # Generations: 100\n",
    "Mininum # of Generations: 80\n",
    "Convergence Criteria: 0.00001000\n",
    "Population Size: 200\n",
    "Initial Fill Percentage: 0.50\n",
    "Mutation Rate: 0.30\n",
    "Crossover Rate: 0.80\n",
    "Crossover Method: SINGLE\n",
    "Mating Method: ROULETTE\n",
    "Elitism is: ON\n",
    "!!With Elitism ON, the probability of GA engineering has been set to 0.00!!\n",
    "##########################################\n",
    "Objective: MAXIMIZE\n",
    "Objective Function: ComputeLikelihood(dist='NRM')\n",
    "Bit Encoding:\n",
    "Real00\tReal01\n",
    "Bits\t16.000000\t16.000000\n",
    "Lower\t41.625069\t0.000100\n",
    "Upper\t42.167238\t1.355424\n",
    "##########################################\n",
    "Generation 1 of 100: Best Score = -131.7597, Early Termination = 1\n",
    "\t[41.8933,0.9053]\n",
    "../src\\GA\\Objective.py:129: RuntimeWarning:\n",
    "\n",
    "divide by zero encountered in log\n",
    "\n",
    "Generation 11 of 100: Best Score = -131.7597, Early Termination = 11\n",
    "\t[41.8933,0.9053]\n",
    "Generation 21 of 100: Best Score = -131.7597, Early Termination = 21\n",
    "\t[41.8933,0.9053]\n",
    "Generation 31 of 100: Best Score = -131.7597, Early Termination = 31\n",
    "\t[41.8933,0.9053]\n",
    "Generation 41 of 100: Best Score = -131.7597, Early Termination = 41\n",
    "\t[41.8933,0.9053]\n",
    "Generation 51 of 100: Best Score = -131.7597, Early Termination = 51\n",
    "\t[41.8933,0.9053]\n",
    "Generation 61 of 100: Best Score = -131.7597, Early Termination = 61\n",
    "\t[41.8933,0.9053]\n",
    "Generation 71 of 100: Best Score = -131.7597, Early Termination = 71\n",
    "\t[41.8933,0.9053]\n",
    "Generation 81 of 100: Best Score = -131.7591, Early Termination = 6\n",
    "\t[41.8943,0.9046]\n",
    "Generation 91 of 100: Best Score = -131.7591, Early Termination = 16\n",
    "\t[41.8943,0.9046]\n",
    "Generation 100 of 100: Best Score = -131.7591, Early Termination = 25\n",
    "\t[41.8943,0.9046]\n",
    "##########################################\n",
    "GA Complete\n",
    "\tUnique Solutions Evaluated - 29702\n",
    "\tTotal Solutions Possible - 4294967296\n",
    "Top 10 Solutions\n",
    "Score\tReal00\tReal01\tFrequency\n",
    "[41.8943,0.9046]\t-131.759125\t41.894313\t0.904622\t0.25\n",
    "[41.8933,0.9053]\t-131.759658\t41.893270\t0.905325\t0.75\n",
    "GA: Started on 2022-02-03T17:24:22.049455\n",
    "\tFinished on 2022-02-03T17:24:35.591523\n",
    "\tElapsed Time = 0.226(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fcb6d-b62a-4dd5-a06a-281b57fd9c31",
   "metadata": {},
   "source": [
    "At the end of the GA runs, the notebook generates a plot, shown here, with a histogram of the sample data and three overlays:\n",
    "- the true known distribution in green\n",
    "- the best distribution found by the GA in blue\n",
    "- the second best distribution found by the GA in purple\n",
    "- the third best distribution found by the GA in red\n",
    "\n",
    "<center><img src='../images/GADistFitResult_20220203172615_NRM_42__1.png' height='1000'></center>\n",
    "\n",
    "For this dataset, the distribution identified as best by the GA is a Gaussian distribution with very close parameters. It is very interesting that the second best is a gamma distribution. This circumstance allows us to make a useful observation about the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e150e0-597b-48c3-8f83-d4ac45d779f2",
   "metadata": {},
   "source": [
    "When comparing maximized likelihood scores among distributions fit to the same data, we are only comparing how well the distribution fits the data - the complexity of the distributional model is not taken into consideration at all. This could result in a complex distribution being selected as best over a much simpler distribution, because of a slight improvement in model fit. In this case, the aforementioned Occam's Razor adjures us to prefer the simpler distribution. Instead of maximizing the likelihood to select the optimal distribution, we can use Information Theoretic Criteria, such as [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion), [SBC](https://en.wikipedia.org/wiki/Bayesian_information_criterion), or [ICOMP](https://www.researchgate.net/publication/228911984_A_new_class_of_information_complexity_ICOMP_criteria_with_an_application_to_customer_profiling_and_segmentation), et al. All three add a complexity penalty to the maximized likelihood:\n",
    "\\begin{align}\n",
    "AIC =& -2\\log l\\left(\\hat{\\theta}\\vert X\\right) + 2\\vert\\theta\\vert\\\\\n",
    "SBC =& -2\\log l\\left(\\hat{\\theta}\\vert X\\right) + \\log n\\vert\\theta\\vert\\\\\n",
    "ICOMP =& -2\\log l\\left(\\hat{\\theta}\\vert X\\right) + 2C_1\\left(\\mathcal{F^{-1}}\\right)\n",
    "\\end{align}\n",
    "\n",
    "The term $\\vert\\theta\\vert$ is the cardinality of the parameters, $C_1$ is the maximal entropic complexity based on the [Kullback-Liebler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), and $\\mathcal{F}$ is the [Fisher information](https://en.wikipedia.org/wiki/Fisher_information), or Hessian matrix estimated with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8d220-c2f1-4bb8-b7a8-7684501b7b7f",
   "metadata": {},
   "source": [
    "## Multivariate Function Minimization\n",
    "\n",
    "<a id=MFM></a>\n",
    "<a href=#top>Go to Top</a>\n",
    "\n",
    "Numerical optimization of mathematical functions is an important topic, and has attracted a lot of research by some of the most brilliant mathematicians and computer scientists over the years. As researchers develop and test novel optimization algorithms, it is important that they can evaluate and compare their strengths and weaknesses. To this end, there are many benchmark functions with known optima that present different challenges to algorithms and allow characterisation of\n",
    "- accuracy & precision\n",
    "- rate of convergence\n",
    "- robustness wrt noise and / or initialization\n",
    "- performance\n",
    "\n",
    "Many of them are listed [here](https://en.wikipedia.org/wiki/Test_functions_for_optimization). The Sphere function, for example, should be relatively easy to minimize, as there is only a single minimum. Others, such as the Rastrigin or Ackley functions, have several local minima, and can be difficult for gradient-following functions to minimize.\n",
    "\n",
    "The [GA Real Optimization - Multivariate Minimzation](./GA_RealOptimization_MultivarMin.ipynb) notebook demonstrates the performance of the GA on 13 of these functions. Since the minima are known, we can assess the accuracy of the GA result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46c5d9-b2e7-435e-b0b9-f3c985279005",
   "metadata": {},
   "source": [
    "For all functions, we run the GA for 200 generations, with a population size of 200. 50 bits were used to encode each real value in the solution. For all functions, the GA evaluated approximately 79,000 unique solutions - an extremely small portion of the solution space. At the end of the GA, we compute the absolute error and Euclidean distance between the true minimum point and the minimum point found by the GA:\n",
    "\\begin{equation}\n",
    "Dist_E = \\sqrt{\\sum_{i=1}^n\\left(T_i-G_i\\right)^2}\n",
    "\\end{equation}\n",
    "Summary results are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb37e41-7f29-4120-a35f-b9483d469402",
   "metadata": {},
   "source": [
    "### Good Performance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47786dee-8138-4984-ab9d-56aace056609",
   "metadata": {},
   "source": [
    "Rastrigin\n",
    "True Minimum Value = 0.000 at [0, 0]\n",
    "GA Best = 0.113 at [-0.00432418482622321, -0.023527982419532023]\n",
    "Error = 0.113\n",
    "Euclidian Distance Between Points = 0.024\n",
    "\n",
    "Ackley\n",
    "True Minimum Value = 0.000 at [0, 0]\n",
    "GA Best = 0.069 at [-0.015572667688368291, -0.013323041354467158]\n",
    "Error = 0.069\n",
    "Euclidian Distance Between Points = 0.020\n",
    "\n",
    "Sphere\n",
    "True Minimum Value = 0.000 at [0, 0, 0, 0]\n",
    "GA Best = 0.178 at [-0.36526966591684307, -0.09238472267452558, -0.16576388751153637, -0.0943361265034337]\n",
    "Error = 0.178\n",
    "Euclidian Distance Between Points = 0.422\n",
    "\n",
    "Goldstein-price\n",
    "True Minimum Value = 3.000 at [0, -1]\n",
    "GA Best = 3.008 at [-0.001462349200918922, -0.9962432216723895]\n",
    "Error = 0.008\n",
    "Euclidian Distance Between Points = 0.004\n",
    "\n",
    "Booth\n",
    "True Minimum Value = 0.000 at [1, 3]\n",
    "GA Best = 0.000 at [1.0043450296306773, 2.98820752986445]\n",
    "Error = 0.000\n",
    "Euclidian Distance Between Points = 0.013\n",
    "\n",
    "Matyas\n",
    "True Minimum Value = 0.000 at [0, 0]\n",
    "GA Best = 0.000 at [-0.026047484920352915, -0.053975941766628566]\n",
    "Error = 0.000\n",
    "Euclidian Distance Between Points = 0.060\n",
    "\n",
    "Levi13\n",
    "True Minimum Value = 0.000 at [1, 1]\n",
    "GA Best = 0.014 at [0.989837206781532, 1.0626076289298254]\n",
    "Error = 0.014\n",
    "Euclidian Distance Between Points = 0.063\n",
    "\n",
    "Himmelblau\n",
    "True Minimum Value = 0.000 at [3.58442, -1.84812]\n",
    "GA Best = 0.003 at [3.5909750549982515, -1.8429214837225123]\n",
    "Error = 0.003\n",
    "Euclidian Distance Between Points = 0.008\n",
    "\n",
    "Easom\n",
    "True Minimum Value = -1.000 at [3.141592653589793, 3.141592653589793]\n",
    "GA Best = -0.982 at [3.0360146243254746, 3.1769915167205625]\n",
    "Error = 0.018\n",
    "Euclidian Distance Between Points = 0.111\n",
    "\n",
    "Styblinsky-Tang\n",
    "True Minimum Value = -117.500 at [-2.903534, -2.903534, -2.903534]\n",
    "GA Best = -117.137 at [-2.9724006891965864, -3.01776800497011, -2.8531270330098106]\n",
    "Error = 0.363\n",
    "Euclidian Distance Between Points = 0.143"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f53b42-c37d-4797-852a-dec6f52ff31b",
   "metadata": {},
   "source": [
    "### Bad Performance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b174aa9-9678-484d-85a4-1f1ab5db2a5c",
   "metadata": {},
   "source": [
    "Rosenbrock\n",
    "Known Minimum Value = 0.000 at [1, 1, 1]\n",
    "GA Best = 1.161 at [0.6859903513170895, 0.49356550478569794, 0.3304072816806869]\n",
    "Error = 1.161\n",
    "Euclidian Distance Between Points = 0.896\n",
    "\n",
    "Beale\n",
    "True Minimum Value = 0.000 at [3, 0.5]\n",
    "GA Best = -12.831 at [-0.25554271094536407, 4.477042922051712]\n",
    "Error = 12.831\n",
    "Euclidian Distance Between Points = 5.140\n",
    "\n",
    "Bukin6\n",
    "True Minimum Value = 0.000 at [-10, 1]\n",
    "GA Best = 0.418 at [10.867977645212083, 1.1811249930355139]\n",
    "Error = 0.418\n",
    "Euclidian Distance Between Points = 20.869"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f2daa-68bd-49ce-bb8d-40afc3593f61",
   "metadata": {},
   "source": [
    "For the 3-dimensional functions, a surface + contour plot is created, annotating the location of the known and best solution found by the GA. A sample of these are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2338b-9f08-4150-bf15-8e15ae398c81",
   "metadata": {},
   "source": [
    "### Ackley\n",
    "This function is challenging because there are very many local minima, which can trap gradient-following optimizers.\n",
    "\\begin{align}\n",
    "f\\left(x, y\\right) =& -20\\exp\\left(-0.2\\sqrt{\\frac{1}{2}\\left(x^2+y^2\\right)}\\right) - \\exp\\left(\\frac{1}{2}\\left(\\cos2\\pi x + \\cos2\\pi y \\right)\\right) + \\exp\\left(1\\right) + 20\\\\\n",
    "&-5\\le x, y\\le 5\\\\\n",
    "f\\left(0, 0\\right) =& 0\\text{ :minima}\n",
    "\\end{align}\n",
    "<center><img src='../images/GAFuncMinResult_20220204152449_Ackley.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cacada-d06a-4fb6-b4f8-de8768bd1de2",
   "metadata": {},
   "source": [
    "### Beale\n",
    "\\begin{align}\n",
    "f\\left(x, y\\right) =& \\left(1.5 - x + xy\\right)^2 + \\left(2.25 - x +xy^2 \\right)^2 + \\left(2.625 - x + xy^3\\right)^2\\\\\n",
    "&-4.5\\le x, y\\le 4.5\\\\\n",
    "f\\left(3, 0.5\\right) =& 0\\text{ :minima}\n",
    "\\end{align}\n",
    "The GA found a solution very far from the actual minimum point, which is odd. This function is difficult for gradient followers because there are very shallow gradients over most of the input domain.\n",
    "<center><img src='../images/GAFuncMinResult_20220204153736_Beale.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f0639-011d-4ee8-ae81-dd114cd1b013",
   "metadata": {},
   "source": [
    "### Booth\n",
    "\\begin{align}\n",
    "f\\left(x, y\\right) =& \\left(x + 2y - 7\\right)^2 + \\left(2x + y - 5\\right)^2\\\\\n",
    "&-10\\le x, y\\le 10\\\\\n",
    "f\\left(1, 3\\right) =& 0\\text{ :minima}\n",
    "\\end{align}\n",
    "This function is difficult for gradient-following optimizers because the gradients are relatively flat in the saddle, but quite steep on the wings. This latter characteristic will likely increase the rate of convergence.\n",
    "<center><img src='../images/GAFuncMinResult_20220204154236_Booth.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efe97f-d682-4d72-9748-291a7710ae75",
   "metadata": {},
   "source": [
    "### Bukin 6\n",
    "\\begin{align}\n",
    "f\\left(x, y\\right) =& 100\\sqrt{\\vert y-0.01x^2\\vert} + 0.01\\vert x + 10\\vert\\\\\n",
    "&-15\\le x \\le 5, -3\\le y \\le3\\\\\n",
    "f\\left(-10, 1\\right) =& 0\\text{ :minima}\n",
    "\\end{align}\n",
    "This is the function on which the GA performed the worst, as measured by Euclidean distance between the true and bound minima.\n",
    "\n",
    "<center><img src='../images/GAFuncMinResult_20220204154443_Bukin6.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618761a-ce2c-4e5f-8d2a-401cfdd5010a",
   "metadata": {},
   "source": [
    "### Easom\n",
    "\\begin{align}\n",
    "f\\left(x, y\\right) =& -\\cos\\left(x\\right)\\cos\\left(y\\right)\\exp\\Big(-\\big(\\left(x-\\pi\\right)^2 + \\left(y-\\pi\\right)^2\\big)\\Big)\\\\\n",
    "&-100\\le x,y \\le 100\\\\\n",
    "f\\left(\\pi, \\pi\\right) =& 0\\text{ :minima}\n",
    "\\end{align}\n",
    "The gradient of this function is $0$ everywhere except for very near the minimum point, making it very challenging for gadient-based algorithms.\n",
    "<center><img src='../images/GAFuncMinResult_20220204155742_Easom.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868931bb-8977-43ab-9625-2d68b9766304",
   "metadata": {},
   "source": [
    "<a href=#top>Go to Top</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
