{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0669b26f-da8b-4693-9c22-f8115aeb8864",
   "metadata": {},
   "source": [
    "# Genetic Algorithms\n",
    "## Evolutionary Algorithms for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e307aa7-917b-4423-9bdc-ab63b5ad6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stt\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "# to use plotly offline, need to initialize with a plot\\n\",\n",
    "plyoff.init_notebook_mode(connected=True)\n",
    "init = go.Figure(data=[go.Scatter({'x':[1, 2], 'y':[42, 42], 'mode':'markers'})], layout=go.Layout(title='Init', xaxis={'title':'x'}, height=100, width=100))\n",
    "plyoff.iplot(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ed8c3-0a04-464a-9e70-55c9f91125fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mathematical Optimization\n",
    "Optimization is the process of finding some numerical values that generate a minimum or maximum value for a specified function. Examples include finding the best parameters for a statistical distribution fit to some data, numerically solving differential equations, or feature selection in machine learning.\n",
    "\n",
    "There are many types and classes of optimization algorithms. Most that have been invented by mathematicianas and computer scientists rely on function derivatives / gradients. Anybody who's studied the topic even slightly will likely remember [Newton-Raphson](https://en.wikipedia.org/wiki/Newton%27s_method) or the [BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) - the latter of which even need the second derivaties (the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)). Mathematical optimization algorithms typically iterate over two steps:\n",
    "\n",
    "1.  evaluate current solution\n",
    "2. find new solution to try\n",
    "\n",
    "A series of individual solutions are identified and evluated, until the sequence converges to a solution.\n",
    "\n",
    "Gradient-following methods can have good properties, but also two major issues.\n",
    "\n",
    "1. The first is the need to compute derivatives. This can often be very difficult - even assuming derivatives can be analytically solved - and time consuming. Furthermore, not all functions we wish to optimizte even have a derivative. What is the derivative of an accuracy loss function for a [Decision Tree Classifier](https://en.wikipedia.org/wiki/Decision_tree_learning)?\n",
    "\n",
    "2. The second issue is that gradient-followers can easily get stuck in local optima, rather than finding a global optimum point. Most such algorithms rely on being provided an initial values, at which point the necessary derivatives are computed to determine the direction (and perhaps distance) to find the next point to evaluate. Depending on the curvature of the function to optimize, and the initial solution, the algorithm may get stuck in a local, not global, optimum.\n",
    "\n",
    "The figure generated below demonstrates this second point. The curve to be maximized has two optima with a saddle point in between. Four possible initial values are shown. When the curve's gradient is evaluated at the two $x_0$ points in red, an optimization algorithm will converge to the local optimum. The two in greed will converge to the global optimum. In general, any initial value on the right side of the black vertical line will cause an optimization algorithm to converge to the local optimum; initial values to the left of it will converge to the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b3508-3de3-43b0-a8f9-1b9fed5cb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "np.random.seed(42)\n",
    "X1 = stt.norm(loc=0, scale=1).rvs(500)\n",
    "X2 = stt.norm(loc=2, scale=0.5).rvs(500)\n",
    "data = np.r_[X1, X2]\n",
    "\n",
    "# prep for kde\n",
    "mn, mx = min(data), max(data)\n",
    "x= np.linspace(mn, mx, 200)\n",
    "\n",
    "# kde\n",
    "kde = stt.gaussian_kde(data, bw_method=0.25)\n",
    "y = kde(x)\n",
    "\n",
    "# create the annotation\n",
    "x1 = -1\n",
    "y1 = kde(x1)[0]\n",
    "ann1 = dict(x=x1, y=y1, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Local Optimum}$'%x1, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x2 = 0.40\n",
    "y2 = kde(x2)[0]\n",
    "ann2 = dict(x=x2, y=y2, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ←; Local Optimum}$'%x2, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#ff0000\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#ff0000\")\n",
    "x3 = 1.5\n",
    "y3 = kde(x3)[0]\n",
    "ann3 = dict(x=x3, y=y3, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient →; Global Optimum}$'%x3, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x4 = 3.0\n",
    "y4 = kde(x4)[0]\n",
    "ann4 = dict(x=x4, y=y4, xref='x1', yref='y1', text='$x_0 = %0.2f\\\\text{; Gradient ; Global Optimum}$'%x4, showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#00FF00\", opacity=0.8,\n",
    "            font={'color':'#000000'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#00FF00\")\n",
    "x5 = 0.78698325\n",
    "y5 = kde(x5)[0]\n",
    "ann5 = dict(x=x5, y=y5, xref='x1', yref='y1', text='← Fails; Succeeds →', showarrow=True,\n",
    "            bordercolor=\"#c7c7c7\", borderwidth=2, borderpad=4, bgcolor=\"#6d72f1\", opacity=0.8,\n",
    "            font={'color':'#ffffff'}, align=\"center\", arrowhead=2, arrowsize=1, arrowwidth=2,\n",
    "            arrowcolor=\"#636363\")\n",
    "\n",
    "# plot\n",
    "trcs = [go.Scatter(x=x, y=y, mode='lines', name='Kernel Density Estimate'),\n",
    "        go.Scatter(x=[x5, x5], y=[min(y), max(y)], mode='lines', line={'color':'black'})]\n",
    "fig = go.Figure(data=trcs, layout=go.Layout(title='Shortfall of Gradient Following'))\n",
    "anns = list(fig['layout']['annotations'])\n",
    "anns.extend([ann1, ann2, ann3, ann4, ann5])\n",
    "fig.update_layout( annotations=anns)\n",
    "#plyoff.plot(fig, include_mathjax='cdn')\n",
    "plyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3600b6c-f257-4268-8d85-0265dba18e9e",
   "metadata": {},
   "source": [
    "## Non-Gradent Following Optimization Algorithms\n",
    "\n",
    "There are several types of mathematical optimization algorithms which similarly operate on a sequence of individual solutions, but don't use derivatives. I am familiar with [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing) and [Golden Section Search](https://en.wikipedia.org/wiki/Golden-section_search) opimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb67cf5-2e9b-4f91-aadb-4b63a7afd19e",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithms\n",
    "The term [Evolutionary Algorithm (EA)](https://en.wikipedia.org/wiki/Evolutionary_algorithm) refers to a population-based metaheuristic optimization algorithm, and is a subset of evolutionary computation. Broadly, evolutionary algorithms are designed around concepts which come from biological evolution. There are several classes of evolutionary algorithms:\n",
    "\n",
    "- Differential Evolution\n",
    "- Evolutionary Programming\n",
    "- Evolutionary Strategy\n",
    "- Genetic Algorithm\n",
    "- Genetic Programming ([see here](https://github.com/ahowe42/baseball))\n",
    "- Learning Classifier System\n",
    "- Neuroevolution\n",
    "\n",
    "This set of lectures is focused on the Genetic Algorithm (GA), but could potentially be extended to include [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04162e2f-4de0-46aa-89a7-38967b81f865",
   "metadata": {},
   "source": [
    "## Other Gradient Eschewing Algorithms\n",
    "In addition to EA's, there are several other types of metaheuristic optimization algorithms that are based on the idea of optimizing with a population of potential solutions. These include:\n",
    "\n",
    "- [Ant Colony Optimization - or Traveling Ant Colony Optimization (TACO)](https://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms)\n",
    "- [Particle Swarm Optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization)\n",
    "- [Bees Algorithm](https://en.wikipedia.org/wiki/Bees_algorithm)\n",
    "- [Adaptive Dimensional Search](https://en.wikipedia.org/wiki/Adaptive_dimensional_search)\n",
    "- [Gaussian Adaptation](https://en.wikipedia.org/wiki/Gaussian_adaptation)\n",
    "- Harmony Search - special case of [Evolution Strategy](https://en.wikipedia.org/wiki/Evolution_strategy)\n",
    "\n",
    "I am only familiar with a few of these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0e191-3b93-4afd-88c4-bde661d6d9a9",
   "metadata": {},
   "source": [
    "## Genetic Algorithm\n",
    "The genetic algorithm (GA) is a stochastic population-based metaheuristic optimization algorithm, that borrows concepts from biological evolution. In the GA, a solution to an optimization problem is represented as a binary string of length `n`. In the GA parlance, this is metaphorically called an *individual*, or *chromosome*. Each solution is part of an ensemble of solutions which are considered together; this is called the *population*. The function to be optimized is called the *objective function*, or the *fitness function* - the latter is a metaphor to the biological concept of \"survival of the fittest\".\n",
    "\n",
    "Starting from an initial population of `P` individuals, the GA iterates over a few steps:\n",
    "\n",
    "1. score the fitness of each individuals in the population\n",
    "2. rank and select each individuals for mating\n",
    "3. mate pairs of individuals to create a new population\n",
    "4. apply any GA operators\n",
    "\n",
    "Each population of individuals is called a *generation*. There are several ways to rank and select individuals for mating. There are also several operators that can be used in the GA, mostly related to creating a new generation.\n",
    "\n",
    "The semantic meaning of the binary string as a solution to optimizing an objective function (an individual being the most fit in it's environment) depends on the context. For example, if the GA is being used to optimize a real-valued function, the string could be a digital representation of possible real values. The binary string could represent selection flags for a feature selection problem.\n",
    "\n",
    "In [this research article](https://www.researchgate.net/publication/301770005_Regularized_SVM_Classification_with_a_new_Complexity-Driven_Stochastic_Optimizer), I used the GA to simultaneously select a subset of features and one of 9 kernel functions. The same binary string had one portion interpreted as binary flags, and the other portion as digital representations of the numbers 1 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fde684-46b8-40e2-8261-8098c9d8c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print individuals\n",
    "printIndiv = lambda x: ''.join(['%d'%i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce1b15-776a-4fc6-a15e-cc1cd5d7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' generate a sample population with scores '''\n",
    "# generate the population and scores\n",
    "n = 10\n",
    "P = 4\n",
    "np.random.seed(42)\n",
    "population = np.random.rand(P, n) > 0.5\n",
    "fitness = np.random.rand(P)\n",
    "\n",
    "# sort\n",
    "stdIndex = np.argsort(fitness)[::-1]\n",
    "population = population[stdIndex]\n",
    "fitness = fitness[stdIndex]\n",
    "\n",
    "# talk\n",
    "print('Sample population with %d %d-length individuals'%(P,n))\n",
    "for indx, (score, individual) in enumerate(zip(fitness, population)):\n",
    "    print('%d: %s = %0.3f'%(indx, printIndiv(individual), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b1fa4-51b2-4a6b-a2c7-52853198aa4b",
   "metadata": {},
   "source": [
    "### Mating Ranking & Selection\n",
    "In the GA, mating is the process of combining two individuals to generate new individuals. I generally have two *parent* solutions mate to create a pair of *child* solutions. I do this is to keep a constant population size, but it's not required. For example, mating could choose to create, based on a randomized choice either:\n",
    "\n",
    "- a single offspring + new random individual\n",
    "- a pair of offspring\n",
    "\n",
    "The new random individual in the first option could be thought of as *adoption*.\n",
    "\n",
    "I have generally used two approaches to mating ranking & selection.\n",
    "\n",
    "#### Sorted\n",
    "In biology, it is generally the case that individuals that are similarly fit for their environment mate together. The metaphor generally holds for the GA, in that solutions with similar objective function scores are mated. This doesn't have to be the case. For example, we could mate pairs of solutions best-fitness to worst-fitness. This approach may help better explore the solution space, but I've never used it. \n",
    "\n",
    "This approach to mate ranking and selection is simple, and has the property that each individual mates exactly and only one time. For this, all individuals are sorted according to their fitness scores, then paired off in sequences, so there are $P/2$ mating pairs generated.\n",
    "\n",
    "#### Roulette\n",
    "In biology, it is generally the case that the most fit individuals mate the most, thus propagating their successful genes. This metaphor holds by design with the roulette method for generating mating pairs.\n",
    "\n",
    "The roulette method starts by sorting all individuals according to their fitness scores, then generating a biased roulette bar, in which the individual bins are of gradually decreasing size as computed here and visualized for $P=4$ below:\n",
    "\\begin{equation}\n",
    "b_i = \\frac{2i}{n\\left(n+1\\right)}, i=1,\\ldots,P\\text{.}\n",
    "\\end{equation}\n",
    "\n",
    "<center><img src='./roulette_selection.png' width='400' height='200'></center>\n",
    "\n",
    "When the cumulative sum of these bin widths is computed, we get upper bounds for the roulette bins, which completely partition the [0, 1] interval. Each bin corresponds to an individual in the population; since the population was already sorted by fitness score, the wider bins correspond to the most fit individuals.\n",
    "\n",
    "Since we don't want the population to grow, we will generate $P/2$ mating pairs. To do so, $P$ random numbers are generated uniformly from [0, 1] and placed in the appropriate bin. For each random variate in the $i^\\text{th}$ bin, the corresponding individual will be selected to mate. In this way, individuals with a better fitness score are overrepresented in the mating pool. The last step specific to this\n",
    "method is to randomly permute the ordering of the individuals in the mating pool.\n",
    "\n",
    "Note that this means that, while the most fit individuals will tend to mate the most frequently, they won't just mate with individuals with similar fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ac71e-7341-463f-8b48-57a3d0124710",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - sorted method '''\n",
    "# skipping sorting, as the population is already sorted\n",
    "pairs = np.reshape(range(P), (P//2, 2))\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26e359-8f05-4564-a0be-c386f0e996fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' pair individuals for mating - roulette method '''\n",
    "# generate the bounds and show the bins\n",
    "binUBounds = np.cumsum(2*np.linspace(P, 1, P)/(P*(P + 1.0)))\n",
    "bnds = [0] + binUBounds.tolist()\n",
    "print('Roulette bins: %r'%[('%0.2f'%f, '%0.2f'%t) for f, t in zip(bnds[:-1], bnds[1:])])\n",
    "\n",
    "# generate mating frequencies\n",
    "np.random.seed(1906)\n",
    "rands_in_bins = np.repeat(np.random.rand(P), P) >= np.tile(binUBounds, P)\n",
    "pairs = np.reshape(np.random.permutation(np.sum(np.reshape(rands_in_bins, [P]*2), axis=1)), (P//2, 2))\n",
    "\n",
    "# talk\n",
    "for (indx, pair) in enumerate(pairs):\n",
    "    print('Mating pair %d: %s (%0.3f) <-> %s (%0.3f)'%(indx, printIndiv(population[pair[0]]), fitness[pair[0]],\n",
    "                                                       printIndiv(population[pair[1]]), fitness[pair[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7ecdb-5f18-4300-82c9-dc3459bf445b",
   "metadata": {},
   "source": [
    "### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92cfbf-b233-4879-90c7-3348068d5d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5f39fd-e4d7-4956-b2bc-2715d949aa72",
   "metadata": {},
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e5a3b-3f04-4478-b34d-c2cdd539828d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ae9a31f-f592-499b-9304-c4725c389242",
   "metadata": {},
   "source": [
    "### GA Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4b21a-b49f-4fa9-a2a3-e99b16d25933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "720fd6ef-18e9-43f8-a4e8-15dd874242f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elitism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce80aa5-81e1-4925-92a9-c9f674442f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb64e6-98b1-4d96-9c4b-dc72cb32b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploitation and exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
